# Chapter 3: Coding Attention Mechanisms

&nbsp;
## 章节主要代码

- [01_main-chapter-code](01_main-chapter-code) 包含本章节主要代码和习题解答

&nbsp;
## Bonus Materials

- [02_bonus_efficient-multihead-attention](02_bonus_efficient-multihead-attention) 实现了不同变体的多头注意力机制，并进行了比较
- [03_understanding-buffers](03_understanding-buffers) 解释了 PyTorch 缓冲区的概念，这是实现本章节因果注意力机制的关键



在下面的视频中，提供了一些章节内容的补充材料。

<br>
<br>

[![Link to the video](https://img.youtube.com/vi/-Ll8DtpNtvk/0.jpg)](https://www.youtube.com/watch?v=-Ll8DtpNtvk)
