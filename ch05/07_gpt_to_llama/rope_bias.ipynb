{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoPE常规的直接实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotary_matrix(seq_len: int, dim: int, base: int = 10000) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"生成RoPE的旋转矩阵\"\"\"\n",
    "    # 生成不同频率的正弦和余弦值\n",
    "    theta = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))  # shape为[dim//2]\n",
    "    # 生成位置索引\n",
    "    position = torch.arange(seq_len).float()  # shape为[seq_len]\n",
    "    # 计算每个位置和维度对应的角度\n",
    "    theta = torch.outer(position, theta)  # 计算外积，其中第(i, j)个元素是position[i] * theta[j]；shape为[seq_len, dim//2]\n",
    "    # 计算正弦和余弦值\n",
    "    cos = torch.cos(theta)  # shape为[seq_len, dim//2]\n",
    "    sin = torch.sin(theta)  # shape为[seq_len, dim//2]\n",
    "    return cos, sin\n",
    "\n",
    "\n",
    "def apply_rotary_embedding(x: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"应用旋转位置编码\"\"\"\n",
    "    # 假设x的形状为[batch_size, seq_len, dim]\n",
    "    # 将向量视为复数，每两个维度一组\n",
    "    x_reshape = x.view(*x.shape[:-1], -1, 2)  # shape为[batch_size, seq_len, dim//2, 2]，即沿着特征维度拆分\n",
    "    \n",
    "    # 构建正弦和余弦矩阵，使其与x_reshape形状匹配\n",
    "    cos_expanded = cos.view(1, cos.shape[0], cos.shape[1], 1)  # shape为[1, seq_len, dim//2, 1]\n",
    "    sin_expanded = sin.view(1, sin.shape[0], sin.shape[1], 1)  # shape为[1, seq_len, dim//2, 1]\n",
    "    \n",
    "    # 旋转操作（复数乘法）\n",
    "    # [x_real, x_imag] * (cos + i*sin) = [x_real*cos - x_imag*sin, x_real*sin + x_imag*cos]\n",
    "    x_out_1 = x_reshape[:, :, :, 0:1] * cos_expanded - x_reshape[:, :, :, 1:2] * sin_expanded\n",
    "    x_out_2 = x_reshape[:, :, :, 0:1] * sin_expanded + x_reshape[:, :, :, 1:2] * cos_expanded\n",
    "    \n",
    "    # 合并结果\n",
    "    x_out = torch.cat([x_out_1, x_out_2], dim=-1)  # shape为[batch_size, seq_len, dim//2, 2]\n",
    "    return x_out.view(*x.shape)\n",
    "\n",
    "\n",
    "# 示例用法\n",
    "def apply_rope(x: torch.Tensor, rotary_matrix_function: Callable, seq_len: int = None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    对输入向量应用RoPE位置编码\n",
    "    x: 输入向量\n",
    "    seq_len: 不同情况下输入不同\n",
    "    \"\"\"\n",
    "    _, x_seq_len, dim = x.shape\n",
    "    t_seq_len = seq_len if seq_len is not None else x_seq_len\n",
    "    cos, sin = rotary_matrix_function(t_seq_len, dim)\n",
    "    return apply_rotary_embedding(x, cos, sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入形状: torch.Size([2, 10, 512])\n",
      "输出形状: torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "rotary_matrix_function = get_rotary_matrix\n",
    "\n",
    "batch_size, seq_len, dim = 2, 10, 512\n",
    "x = torch.randn(batch_size, seq_len, dim)\n",
    "\n",
    "# 应用RoPE\n",
    "x_with_rope = apply_rope(x, rotary_matrix_function)\n",
    "print(f\"输入形状: {x.shape}\")\n",
    "print(f\"输出形状: {x_with_rope.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 外扩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NTK版本的外扩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ntk_rotary_matrix(seq_len: int, dim: int, base: int = 10000, scaling_factor: float = 1.0) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    NTK缩放版本的RoPE旋转矩阵\n",
    "    seq_len: 期望扩展后的序列长度\n",
    "    dim: 向量维度\n",
    "    base: 基础频率\n",
    "    scaling_factor: 缩放因子；扩展后序列长度和原始序列长度的比值\n",
    "    \"\"\"\n",
    "    # 应用缩放因子\n",
    "    effective_base = base * (scaling_factor ** (dim / (dim - 2)))\n",
    "    \n",
    "    # 生成不同频率的基础角度\n",
    "    theta = 1.0 / (effective_base ** (torch.arange(0, dim, 2).float() / dim))\n",
    "    \n",
    "    # 生成位置索引\n",
    "    position = torch.arange(seq_len).float()\n",
    "    \n",
    "    # 计算每个位置和维度对应的角度\n",
    "    theta = torch.outer(position, theta)\n",
    "    \n",
    "    # 计算正弦和余弦值\n",
    "    cos = torch.cos(theta)\n",
    "    sin = torch.sin(theta)\n",
    "    return cos, sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入形状: torch.Size([2, 20, 512])\n",
      "输出形状: torch.Size([2, 20, 512])\n"
     ]
    }
   ],
   "source": [
    "rotary_matrix_function = partial(get_ntk_rotary_matrix, scaling_factor=2.0)\n",
    "\n",
    "batch_size, seq_len, dim = 2, 20, 512  # 此处将seq_len设置为20，与scaling_factor=2.0相匹配\n",
    "x = torch.randn(batch_size, seq_len, dim)\n",
    "\n",
    "# 应用RoPE\n",
    "x_with_rope = apply_rope(x, rotary_matrix_function)\n",
    "print(f\"输入形状: {x.shape}\")\n",
    "print(f\"输出形状: {x_with_rope.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_interpolation_rope1(seq_len: int, dim: int, target_len: int,\n",
    "                                   base: int = 10000) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    通过线性插值扩展RoPE位置编码\n",
    "    seq_len: 原始序列长度\n",
    "    dim: 向量维度\n",
    "    target_len: 目标序列长度\n",
    "    base: 基础频率\n",
    "    \"\"\"\n",
    "    # 原始RoPE编码\n",
    "    original_cos, original_sin = get_rotary_matrix(seq_len, dim, base)  # [seq_len, dim//2]\n",
    "    \n",
    "    # 创建两个全零向量用于存储插值后结果\n",
    "    interpolated_cos = torch.zeros(target_len, original_cos.size(1))\n",
    "    interpolated_sin = torch.zeros(target_len, original_sin.size(1))\n",
    "    \n",
    "    for i in range(original_cos.size(1)):  # 逐一进行一维线性插值\n",
    "        interpolated_cos[:, i] = torch.nn.functional.interpolate(\n",
    "            original_cos[:, i].unsqueeze(0).unsqueeze(0),  # original_cos[:, i]是复数维度中第i维的所有seq_len长度的序列，即[\\theta_0, ..., \\theta_{seq_len-1}]\n",
    "            size=(target_len,),  # 以线性插值的方式扩展到目标长度target_len\n",
    "            mode='linear',\n",
    "            align_corners=True  # 确保插值时原始序列的两端点精确对齐\n",
    "        ).squeeze(0).squeeze(0)\n",
    "        \n",
    "        interpolated_sin[:, i] = torch.nn.functional.interpolate(\n",
    "            original_sin[:, i].unsqueeze(0).unsqueeze(0),\n",
    "            size=(target_len,),\n",
    "            mode='linear',\n",
    "            align_corners=True\n",
    "        ).squeeze(0).squeeze(0)\n",
    "    \n",
    "    return interpolated_cos, interpolated_sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入形状: torch.Size([2, 20, 512])\n",
      "输出形状: torch.Size([2, 20, 512])\n"
     ]
    }
   ],
   "source": [
    "rotary_matrix_function = partial(get_linear_interpolation_rope1, target_len=20)\n",
    "\n",
    "seq_len = 10  # 训练长度\n",
    "batch_size, target_len, dim = 2, 20, 512  # 此处将target_length为目标长度\n",
    "x = torch.randn(batch_size, target_len, dim)\n",
    "\n",
    "# 应用RoPE\n",
    "x_with_rope = apply_rope(x, rotary_matrix_function, seq_len=seq_len)\n",
    "print(f\"输入形状: {x.shape}\")\n",
    "print(f\"输出形状: {x_with_rope.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_interpolation_rope2(seq_len: int, dim: int, target_len: int,\n",
    "                                   base: int = 10000) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    通过线性插值扩展RoPE位置编码\n",
    "    seq_len: 原始序列长度\n",
    "    dim: 向量维度\n",
    "    target_len: 目标序列长度\n",
    "    base: 基础频率\n",
    "    \"\"\"\n",
    "    # 原始RoPE编码\n",
    "    original_cos, original_sin = get_rotary_matrix(seq_len, dim, base)\n",
    "    \n",
    "    # 将张量转换为正确的维度以使用二维插值\n",
    "    # 添加两个维度，使其形状为 [1, 1, seq_len, dim//2]\n",
    "    original_cos_expanded = original_cos.unsqueeze(0).unsqueeze(0)\n",
    "    original_sin_expanded = original_sin.unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    # 使用二维插值\n",
    "    interpolated_cos = torch.nn.functional.interpolate(\n",
    "        original_cos_expanded,\n",
    "        size=(target_len, original_cos.size(1)),\n",
    "        mode='bilinear',\n",
    "        align_corners=True\n",
    "    ).squeeze(0).squeeze(0)\n",
    "    \n",
    "    interpolated_sin = torch.nn.functional.interpolate(\n",
    "        original_sin_expanded,\n",
    "        size=(target_len, original_sin.size(1)),\n",
    "        mode='bilinear',\n",
    "        align_corners=True\n",
    "    ).squeeze(0).squeeze(0)\n",
    "    \n",
    "    return interpolated_cos, interpolated_sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入形状: torch.Size([2, 20, 512])\n",
      "输出形状: torch.Size([2, 20, 512])\n"
     ]
    }
   ],
   "source": [
    "rotary_matrix_function = partial(get_linear_interpolation_rope2, target_len=20)\n",
    "\n",
    "seq_len = 10  # 训练长度\n",
    "batch_size, target_len, dim = 2, 20, 512  # 此处将target_length为目标长度\n",
    "x = torch.randn(batch_size, target_len, dim)\n",
    "\n",
    "# 应用RoPE\n",
    "x_with_rope = apply_rope(x, rotary_matrix_function, seq_len=seq_len)\n",
    "print(f\"输入形状: {x.shape}\")\n",
    "print(f\"输出形状: {x_with_rope.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 动态NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dynamic_ntk_scaling_factor(seq_len: int, target_len: int, alpha: float = 1.0) -> float:\n",
    "    \"\"\"计算动态NTK缩放系数\"\"\"\n",
    "    return (target_len / seq_len) ** alpha\n",
    "\n",
    "\n",
    "def get_dynamic_ntk_rotary_matrix(seq_len: int, dim: int, target_len: int, base: int = 10000,\n",
    "                                  alpha: float = 1.0) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"应用动态NTK缩放的RoPE\n",
    "    seq_len: 训练时的原始序列长度\n",
    "    target_len: 目标序列长度\n",
    "    dim: 向量维度\n",
    "    base: 基础频率\n",
    "    alpha: 缩放因子\n",
    "    \"\"\"\n",
    "    # 计算缩放因子\n",
    "    scaling_factor = compute_dynamic_ntk_scaling_factor(seq_len, target_len, alpha)\n",
    "    \n",
    "    # 获取缩放后的旋转矩阵\n",
    "    cos, sin = get_ntk_rotary_matrix(target_len, dim, base, scaling_factor)\n",
    "\n",
    "    return cos, sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入形状: torch.Size([2, 20, 512])\n",
      "输出形状: torch.Size([2, 20, 512])\n"
     ]
    }
   ],
   "source": [
    "rotary_matrix_function = partial(get_dynamic_ntk_rotary_matrix, target_len=20)\n",
    "\n",
    "seq_len = 10  # 训练长度\n",
    "batch_size, target_len, dim = 2, 20, 512  # 此处将target_len为目标长度\n",
    "x = torch.randn(batch_size, target_len, dim)\n",
    "\n",
    "# 应用RoPE\n",
    "x_with_rope = apply_rope(x, rotary_matrix_function, seq_len=seq_len)\n",
    "print(f\"输入形状: {x.shape}\")\n",
    "print(f\"输出形状: {x_with_rope.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
