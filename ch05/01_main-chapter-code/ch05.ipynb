{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第五章：在无标签数据上预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib verison: 3.7.5\n",
      "numpy verison: 1.26.4\n",
      "tiktoken verison: 0.8.0\n",
      "torch verison: 2.0.1+cu118\n",
      "tensorflow is not installed\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",\n",
    "    \"numpy\",\n",
    "    \"tiktoken\",\n",
    "    \"torch\",\n",
    "    \"tensorflow\"\n",
    "]\n",
    "for p in pkgs:\n",
    "    try:\n",
    "        print(f\"{p} verison: {version(p)}\")\n",
    "    except ImportError:\n",
    "        print(f\"{p} is not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 本章节实现训练和评估一个预训练LLM的初步代码\n",
    "- 结尾也将OpenAI发布的预训练权重加载到本节实现的模型中\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/chapter-overview.webp\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 本章节覆盖的主体如下图所示\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/02.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 评估生成文本模型\n",
    "- 先使用之前章节中的代码初始化一个GPT模型进行一个简短的回顾\n",
    "- 然后讨论评价LLMs的基础指标/metrics\n",
    "- 最后将评价指标应用到训练和测试数据集\n",
    "\n",
    "### 5.1.1 使用GPT生成文本\n",
    "- 使用之前的代码初始化一个GPT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # 设置为评估模式，关闭dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上面使用了0.1的dropout，但现在训练LLM时不使用dropout已经相对常见\n",
    "- 现代的LLM也不在`nn.Linear`层中使用偏置向量（不同于早期的GPT模型），这是通过设置`\"qkv_bias\": False`实现的\n",
    "- 将上下文长度(`context_length`)减少到256个token，以减少训练模型的计算资源需求，而原始的124M参数的GPT-2模型使用了1024个token\n",
    "  - 这样做是为了让更多的读者能够跟随和执行代码示例，而原始的124M参数的GPT-2模型使用了1024个token\n",
    "  - 然而，请随意增加`context_length`到1024个token（这不需要任何代码更改）\n",
    "  - 稍后也会从预训练权重加载一个1024 `context_length`的模型\n",
    "\n",
    "- 接下来，使用上一章节的`generate_text_simple`函数生成文本\n",
    "- 此外，还定义了两个功能函数，`text_to_token_ids`和`token_ids_to_text`，用于在token和文本表示之间进行转换，本章节中会使用它们\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-process.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "\n",
    "def text_to_token_ids(text: str, tokenizer: tiktoken.Encoding) -> torch.Tensor:\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # 加一个batch维度\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids: torch.Tensor, tokenizer: tiktoken.Encoding) -> str:\n",
    "    flat = token_ids.squeeze(0)  # 移除添加的batch维度\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx = text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如上所见，模型尚未产生良好的文本，这是因为它还没有经过训练\n",
    "- 如何以数字形式衡量或捕捉\"好文本\"是什么，以便在训练过程中追踪它？\n",
    "- 下一小节介绍用于计算生成输出损失指标的度量，可以使用这些指标来衡量训练进度\n",
    "- 接下来的关于微调LLMs的章节也将介绍更多衡量模型质量的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 计算文本生成损失：交叉熵和困惑度\n",
    "- 假设有一个`inputs`张量，其中包含了2个训练样本（行）的词元（token）ID\n",
    "- 与`inputs`相对应，`targets`包含了希望模型生成的目标词元（token）ID\n",
    "- 注意`targets`是将`inputs`向后移动1个位置得到的，正如在第2章实现数据加载器时所解释的那样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将`inputs`输入模型后，获得了2个输入样例的logits向量，每个样例包含3个tokens\n",
    "- 每个token是一个50,257维的向量，对应词汇表的大小\n",
    "- 应用softmax函数，可以将logits张量转换为相同维度的张量，其中包含概率分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)  # 词表中每个token的概率\n",
    "print(probas.shape)  # shape [batch_size, num_tokens, vocab_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 下图使用了一个非常小的词汇表进行说明，概述了如何将概率分数转换回文本，这是在上一章末尾讨论过的内容\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-to-text.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 正如在上一章中讨论的，可以应用`argmax`函数将概率分数转换为预测的token ID\n",
    "- 上面的softmax函数为每个token生成了一个50,257维的向量；`argmax`函数返回这个向量中最高概率分数的位置，即给定token的预测token ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 因为输入batch中包含两个样例，每个样例三个tokens，所以得到的token IDs也是相同形状的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: \n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Shape of token IDs: \n",
      " torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs: \\n\", token_ids)\n",
    "print(\"Shape of token IDs: \\n\", token_ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果解码上述tokens，可能发现其与希望的预测tokens非常不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这是因为模型还未训练\n",
    "- 为了训练模型，需要知道预测的结果与正确的结果还相差多远\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-index.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目标索引对应的tokens概率如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目标是最大化所有这些值，使它们接近概率1\n",
    "- 在数学优化中，最大化概率分数的对数比最大化概率分数本身更容易；这在本书的范围内不讨论，下面链接资源详细介绍了这个概念：[L8.2 Logistic Regression Loss Function](https://www.youtube.com/watch?v=GxJe0DZvydM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# 计算所有token概率的对数\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 下一步计算平均对数概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目标是使这个平均对数概率尽可能大，通过优化模型权重\n",
    "- 由于对数，最大可能值是0，目前离0还很远\n",
    "\n",
    "- 在深度学习中，不是最大化平均对数概率值，而是最小化平均对数概率的负数；本章节例子中，不是最大化-10.7722，使其接近0，而是最小化10.7722，使其接近0\n",
    "- 负的-10.7722，即10.7722，在深度学习中也称为交叉熵损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pytorch中内部实现了上述计算过程的交叉熵计算函数 `cross_entropy`\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/cross-entropy.webp?123\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在应用`cross_entropy`之前，需要检查logits和targets的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits的shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets的shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对于PyTorch中的`cross_entropy`函数，希望通过在批次维度上合并这些张量来将它们展平"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)  # 将前两维展平\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 注意targets是token IDs，也代表了logits张量中希望最大化的token索引位置\n",
    "- **PyTorch中的`cross_entropy`函数会自动在logits中应用softmax和log-概率计算，内部处理那些需要最大化的token索引位置**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一个和交叉熵损失相关的概念是LLM的困惑度\n",
    "- 困惑度是交叉熵损失的指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 困惑度通常被认为更易于解释，因为它可以被理解为模型在每个步骤中对词汇量（在上述例子中，是48,725个单词或token）的不确定性\n",
    "- 换句话说，困惑度提供了一个衡量模型预测的概率分布与数据集中单词实际分布之间匹配程度的指标\n",
    "- 类似地，损失值越低，模型预测越接近实际分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 计算训练集和验证机的损失\n",
    "- 使用一个相对较小的数据集来训练LLM（实际上，只有一篇短故事）\n",
    "- 原因如下：\n",
    "  - 可以在没有合适GPU的笔记本电脑上几分钟内运行代码示例\n",
    "  - 训练相对较快（几分钟而不是几周），这对于教育目的非常有用\n",
    "  - 使用的是公共领域的文本，可以在不违反任何使用权利或增加仓库大小的情况下包含在GitHub仓库中\n",
    "\n",
    "\n",
    "- 例如，Llama 2 7B在A100 GPU上训练2万亿个token需要184,320个GPU小时\n",
    "  - 截至撰写本文时，8xA100云服务器在AWS上的每小时成本约为30美元\n",
    "  - 因此，通过一个粗略的计算，训练这个LLM将花费184,320 / 8 * 30 = 690,000美元\n",
    " \n",
    "- 下面，使用的是第2章中使用的相同数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n",
    "\n",
    "\n",
    "# The book originally used the following code below\n",
    "# However, urllib uses older protocol settings that\n",
    "# can cause problems for some readers using a VPN.\n",
    "# The `requests` version above is more robust\n",
    "# in that regard.\n",
    "\n",
    "        \n",
    "# import os\n",
    "# import urllib.request\n",
    "\n",
    "# file_path = \"the-verdict.txt\"\n",
    "# url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     with urllib.request.urlopen(url) as response:\n",
    "#         text_data = response.read().decode('utf-8')\n",
    "#     with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "#         file.write(text_data)\n",
    "# else:\n",
    "#     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#         text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过打印第一个和最后99个字符来快速检查文本加载是否正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# First 99 characters\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# Last 99 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5145个tokens，文本非常短，不足以训练一个LLM，但再次强调，这是为了教育目的（稍后也会加载预训练权重）\n",
    "\n",
    "- 接下来，将数据集分为训练集和验证集，并使用第2章中的数据加载器准备LLM训练的批次\n",
    "- 为了可视化目的，下面的图假设`max_length=6`，但对于训练加载器，将`max_length`设置为LLM支持的上下文长度\n",
    "- 下面的图只显示输入token，以便于简化\n",
    "    - 因为训练LLM来预测文本中的下一个词，所以目标看起来与这些输入相同，只是目标向右移动了一个位置\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/batching.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "# 训练/验证集的划分\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(train_data,\n",
    "                                    batch_size=2,\n",
    "                                    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "                                    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "                                    drop_last=True,\n",
    "                                    shuffle=True,\n",
    "                                    num_workers=0)\n",
    "\n",
    "val_loader = create_dataloader_v1(val_data,\n",
    "                                  batch_size=2,\n",
    "                                  max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "                                  stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "                                  drop_last=False,\n",
    "                                  shuffle=False,\n",
    "                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用相对较小的批量大小来减少计算资源需求，因为数据集本身很小\n",
    "- Llama 2 7B训练时使用的批量大小为1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 以下是一个可选的检查，确保数据正确加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 另一个可选的检查是确认token大小在预期的范围内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 接下来，实现一个函数来计算给定批次的交叉熵损失\n",
    "- 此外，实现一个函数来计算数据加载器中用户指定数量的批次的损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch: torch.Tensor, target_batch: torch.Tensor,\n",
    "                    model: torch.nn.Module, device: torch.device) -> torch.Tensor:\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader: torch.utils.data.DataLoader, model: torch.nn.Module,\n",
    "                     device: torch.device, num_batches: int = None) -> float:\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # 如果num_batches超过数据加载器中的总批次数，则减少批次数以匹配数据加载器中的总批次数\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果有支持CUDA的GPU，LLM将使用GPU训练，而不需要任何代码更改\n",
    "- 通过`device`设置，确保数据加载到与LLM模型相同的设备上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583584255642\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Use PyTorch 2.9 or newer for stable mps results\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # 将模型移动到GPU或CPU\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # 为了可重复性，由于数据加载器中的打乱\n",
    "\n",
    "with torch.no_grad(): # 为了效率，禁用梯度跟踪，因为还没有训练\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/10.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 训练一个LLM\n",
    "- 本小节实现训练LLM的完整代码\n",
    "- 主要专注于一个简单的训练函数，如果对使用更高级技术来增强这个训练函数感兴趣，比如学习率预热、余弦退火和梯度裁剪，请参考[Appendix D](../../appendix-D/01_main-chapter-code)\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/train-steps.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 现在开始训练LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.819, Val loss 9.934\n",
      "Ep 1 (Step 000005): Train loss 8.065, Val loss 8.340\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.622, Val loss 7.052\n",
      "Ep 2 (Step 000015): Train loss 6.048, Val loss 6.601\n",
      "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.591, Val loss 6.479\n",
      "Ep 3 (Step 000025): Train loss 5.553, Val loss 6.413\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "Ep 4 (Step 000030): Train loss 5.177, Val loss 6.367\n",
      "Ep 4 (Step 000035): Train loss 4.987, Val loss 6.379\n",
      "Every effort moves you a a, and a a, and the a, and a. Gisburn, and a, and the of the of the of the a. I had the a, and a. I had the of the a of the of the of\n",
      "Ep 5 (Step 000040): Train loss 4.351, Val loss 6.276\n",
      "Every effort moves you, I had been, I had been, I had been a of the of the, I had been, I had been, I had been the of the of the picture, as of the honour of the of the picture of the of the of\n",
      "Ep 6 (Step 000045): Train loss 4.074, Val loss 6.268\n",
      "Ep 6 (Step 000050): Train loss 3.596, Val loss 6.216\n",
      "Every effort moves you know the                                                \n",
      "Ep 7 (Step 000055): Train loss 3.632, Val loss 6.195\n",
      "Ep 7 (Step 000060): Train loss 2.829, Val loss 6.155\n",
      "Every effort moves you know the picture to see the picture.                                          \n",
      "Ep 8 (Step 000065): Train loss 2.407, Val loss 6.140\n",
      "Ep 8 (Step 000070): Train loss 2.048, Val loss 6.190\n",
      "Every effort moves you know,\" was not that, one of the deep arm-chairs forward. \"There: \"Yes, with the fact, as he had a smile behind his painting. It was his pictures--the, the donkey. \"There were, I had\n",
      "Ep 9 (Step 000075): Train loss 1.674, Val loss 6.208\n",
      "Ep 9 (Step 000080): Train loss 1.329, Val loss 6.259\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on the last word.    \"!  \"Oh, I felt him back his head to the donkey--and I saw that, and down the room, I had\n",
      "Ep 10 (Step 000085): Train loss 1.021, Val loss 6.299\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  \"I didn't dabble back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Training completed in 0.23 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 注意在不同的计算机上可能会得到略有不同的损失值，如果它们大致相似（训练损失低于1，验证损失低于7），则没有必要担心\n",
    "- 小的差异通常可能是由于不同的GPU硬件和CUDA版本，或者较新PyTorch版本中的微小变化导致的\n",
    "- 即使在CPU上运行这个示例，也可能会观察到轻微的差异；可能导致差异的一个原因是nn.Dropout在不同操作系统上的行为不同，这取决于PyTorch的编译方式，正如[here on the PyTorch issue tracker](https://github.com/pytorch/pytorch/issues/121595)中讨论的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen: int, tokens_seen: int, train_losses, val_losses) -> None:\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 从上面的结果可以看到模型最初生成的是难以理解的词语字符串，而到了后期，它能够生成语法上或多或少正确的句子\n",
    "- 然而，根据训练集和验证集的损失，可以看到模型开始出现过拟合\n",
    "- 如果检查它在训练结束时写出的几段文字，会发现它们完全照搬自训练集中的内容——模型只是简单地记忆了训练数据\n",
    "- 稍后将介绍一些解码策略，这些策略可以在一定程度上缓解这种记忆现象\n",
    "- 注意，这里出现的过拟合是因为训练集非常非常小，而且对它进行了多次迭代\n",
    "  - 这里的LLM训练主要是出于教育目的，主要想看到模型能够学习生成连贯的文本\n",
    "  - 不可能花费数周或数月的时间在大量昂贵的硬件上训练这个模型，而是在后面加载预训练权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/13.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**如果对使用更高级的技术来增强这个训练函数感兴趣，例如学习率预热、余弦退火和梯度裁剪，请参考[Appendix D](../../appendix-D/01_main-chapter-code)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**如果对更大的训练数据集和更长时间的训练运行感兴趣，请看靠[../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 控制随机性的解码策略\n",
    "- 对于像上面训练的GPT这样相对较小的LLM来说，推理的计算成本相对较低，所以即使在上面的训练过程中使用了GPU，进行推理时也不需要使用GPU\n",
    "- 使用之前在简单训练函数中使用的`generate_text_simple`函数，可以一次生成一个词（或token）\n",
    "- 如第5.1.2节所述，下一个生成的token是词汇表中所有token中概率得分最大的token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "tokend_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]  \n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 即使多次执行上面的`generate_text_simple`函数，LLM也会始终生成相同的输出\n",
    "- 现在引入两个概念，即所谓的解码策略，来修改generate_text_simple：温度缩放（temperature scaling）和top-k采样\n",
    "- 这些策略将允许模型控制生成文本的随机性和多样性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 温度缩放\n",
    "- 之前，总是使用`torch.argmax`来采样下一个token，即具有最高概率的token\n",
    "- 为了增加多样性，可以使用`torch.multinomial(probs, num_samples=1)`，从概率分布中采样\n",
    "- 这里，每个索引被选中的几率与其在输入张量中的概率相对应"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这里简单回顾一下生成下一个词元的过程，假设词汇量非常小，仅用于说明目的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}  # 反向词汇表\n",
    "\n",
    "# 假设 input 是 \"every effort moves you\", 并且 LLM 为下一个token返回以下logits\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# 生成的下一个token如下：\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 不是通过`torch.argmax`来确定最可能的token，而是使用`torch.multinomial(probas, num_samples=1)`从softmax分布中采样来确定最可能的token\n",
    "- 为了说明目的，可以看看使用原始softmax概率对下一个token进行1,000次采样时会发生什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas: torch.Tensor) -> None:\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可以通过称为温度缩放的概念控制概率分布和生成过程\n",
    "- 温度缩放只是一个好听、fancy的名字，本质就是将logits除以一个大于0的数\n",
    "- 大于1的温度将导致应用softmax后的词元概率分布更加均匀\n",
    "- 小于1的温度将导致应用softmax后的概率分布更加具体（更尖锐或更集中）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 注意，根据作系统不同，生成的dropout输出可能看起来不同；可以在[here on the PyTorch issue tracker](https://github.com/pytorch/pytorch/issues/121595)上阅读更多关于这种不一致性的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits: torch.Tensor, temperature: float) -> torch.Tensor:\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "\n",
    "# 测试的温度值列表\n",
    "temperatures = [1, 0.1, 5]\n",
    "\n",
    "# 计算scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可以看到，通过温度0.1进行重新缩放会产生更尖锐的分布，接近于torch.argmax的效果，使得最可能的词几乎总是被选中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "992 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "8 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过温度5重新缩放的概率分布更加均匀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 x closer\n",
      "68 x every\n",
      "55 x effort\n",
      "223 x forward\n",
      "102 x inches\n",
      "50 x moves\n",
      "43 x pizza\n",
      "218 x toward\n",
      "88 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 假设LLM输入为\"every effort moves you\"，使用上述方法有时会产生无意义的文本，比如\"every effort moves you pizza\"，这种情况出现的概率为4.3%（1000次中有43次，具体情况各不相同）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k采样\n",
    "- 为了能够使用更高的温度来增加输出多样性，并降低产生无意义句子的概率，可以将采样的tokens限制在最可能的前k个词元中\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/topk.webp\" width=800px>\n",
    "</p>\n",
    "\n",
    "- 注意，此图中的数字保留小数点后两位，以减少视觉混乱。Softmax行中的值应该加起来等于1.0\n",
    "- 代码实现如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, k=top_k)\n",
    "\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],  # 将所有低于top-k的logits设置为-inf\n",
    "    input=torch.tensor(float(\"-inf\")),  # 如果条件为真，返回-inf\n",
    "    other=next_token_logits  # 如果条件为假，返回原始logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 注意：\n",
    ">\n",
    "> 一个稍微更高效的实现上述代码单元的方法如下：\n",
    ">\n",
    "> ```python\n",
    "> new_logits = torch.full_like(  # 创建包含-inf值的张量\n",
    ">    next_token_logits, -torch.inf\n",
    ">)   \n",
    "> new_logits[top_pos] = next_token_logits[top_pos] # 将top-k值复制到-inf张量中\n",
    "> ```\n",
    "> <br>\n",
    "> 更多细节减 https://github.com/rasbt/LLMs-from-scratch/discussions/326\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 调整文本生成函数\n",
    "\n",
    "- 前两个小节介绍了温度采样和top-k采样\n",
    "- 使用这两个概念来修改之前第4章中用于通过LLM生成文本的`generate_text_simple`函数，创建一个新的`generate`函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx: torch.Tensor, max_new_tokens: int, context_size: int,\n",
    "             temperature: float = 0.0, top_k: int = None, eos_id: int = None) -> torch.Tensor:\n",
    "    # 与之前函数中循环一样，获取logits，只关注最后一步\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]  # 只关注最后一步\n",
    "\n",
    "        # 使用top-k采样\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, k=top_k)\n",
    "            logits = torch.where(\n",
    "                condition=logits < top_logits[:, -1],\n",
    "                input=torch.tensor(float(\"-inf\")).to(logits.device),\n",
    "                other=logits\n",
    "            )\n",
    "\n",
    "        # 使用温度缩放\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)  # [batch_size, context_len]\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # [batch_size, 1]\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # [batch_size, 1]\n",
    "\n",
    "        if idx_next == eos_id:  # 若预测出eos_id，提前结束采样循环\n",
    "            break\n",
    "        \n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # [batch_size, num_tokens+1]\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to happen a good _ himself it was no\n",
      "\"I enough\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 在Pytorch中加载和保存模型权重\n",
    "- 训练LLMs是非常贵的, 因此保存和加载LLMs权重是至关重要的\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/16.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在PyTorch中推荐的方法是通过对.state_dict()方法应用torch.save函数来保存模型权重，即所谓的state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 按以下方法可以将保存的模型权重加载到一个新的`GPTModel`模型实例中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbt/miniconda3/envs/cosyvoice/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Use PyTorch 2.9 or newer for stable mps results\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通常使用自适应优化器如Adam或AdamW而不是常规SGD来训练LLM是很常见的\n",
    "- 这些自适应优化器为每个模型权重存储额外的参数，因此如果计划稍后继续预训练，保存这些参数也是有意义的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),  # 模型权重\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),  # 优化器相关参数\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 加载OpenAI发布的预训练模型\n",
    "\n",
    "- 之前，出于教育目的使用一本非常小的短篇故事书训练了一个小型GPT-2模型\n",
    "- 有兴趣的读者也可以在[../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)中找到在完整的Project Gutenberg图书语料库上进行的更长时间的预训练运行\n",
    "- 幸运的是，不必花费数万到数十万美元在大型预训练语料库上预训练模型，而是可以加载由OpenAI提供的预训练权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "⚠️ **注意: 某些读者可能会在本节中遇到问题，这是由于TensorFlow兼容性问题，特别是在某些Windows系统上。这里需要TensorFlow仅仅是为了加载原始的OpenAI GPT-2权重文件，然后将其转换为PyTorch格式。如果遇到与TensorFlow相关的问题，可以使用下面的替代代码，而不是本节中剩余的代码。这个替代方案基于预先转换的PyTorch权重，使用的是前一节中描述的相同转换过程创建的。\n",
    "有关详细信息，请参考该notebook：\n",
    "[../02_alternative_weight_loading/weight-loading-pytorch.ipynb](../02_alternative_weight_loading/weight-loading-pytorch.ipynb) notebook.**\n",
    "\n",
    "```python\n",
    "file_name = \"gpt2-small-124M.pth\"\n",
    "# file_name = \"gpt2-medium-355M.pth\"\n",
    "# file_name = \"gpt2-large-774M.pth\"\n",
    "# file_name = \"gpt2-xl-1558M.pth\"\n",
    "\n",
    "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    print(f\"Downloaded to {file_name}\")\n",
    "\n",
    "gpt = GPTModel(BASE_CONFIG)\n",
    "gpt.load_state_dict(torch.load(file_name, weights_only=True))\n",
    "gpt.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpt.to(device);\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 首先，一些样板代码用于从OpenAI下载文件并将权重加载到Python中\n",
    "- 由于OpenAI使用了[TensorFlow](https://www.tensorflow.org/)，需要安装和使用TensorFlow来加载权重；[tqdm](https://github.com/tqdm/tqdm)是一个进度条库\n",
    "- 取消注释并运行下一个单元格以安装所需的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting tensorflow\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/2b/b6/86f99528b3edca3c31cad43e79b15debc9124c7cbc772a8f8e82667fd427/tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.8/644.8 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/dbt/.local/lib/python3.10/site-packages (4.66.5)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/dbt/.local/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/dbt/.local/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/dbt/.local/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/1d/fc/716c1e62e512ef1c160e7984a73a5fc7df45166f2ff3f254e71c58076f7c/libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/23/cd/066e86230ae37ed0be70aae89aabf03ca8d9f39c8aea0dec8029455b5540/opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Requirement already satisfied: packaging in /home/dbt/miniconda3/envs/cosyvoice/lib/python3.10/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/dbt/miniconda3/envs/cosyvoice/lib/python3.10/site-packages (from tensorflow) (4.25.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/dbt/miniconda3/envs/cosyvoice/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/dbt/miniconda3/envs/cosyvoice/lib/python3.10/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/dbt/miniconda3/envs/cosyvoice/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/4f/bd/de8d508070629b6d84a30d01d57e4a65c69aa7f5abe7560b8fad3b50ea59/termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/dbt/.local/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/90/ec/00759565518f268ed707dcc40f7eeec38637d46b098a1f5143bff488fe97/wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/5d/b7/7e7b7bb6bb18baf156fd4f2f5b254150dcdd6cbf0def1ee427a2fb2bfc4d/grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/5d/12/4f70e8e2ba0dbe72ea978429d8530b0333f0ed2140cc571a48802878ef99/tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/95/e6/4179c461a5fc43e3736880f64dbdc9b1a5349649f0ae32ded927c0e3a227/keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.2.0,>=1.26.0 in /home/dbt/miniconda3/envs/cosyvoice/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d8/fa/0b6a59a1043c53d5d287effa02303bd248905ee82b25143c7caad8b340ad/h5py-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/16/d8/4502e12c6a10d42e13a552e8d97f20198e3cf82a0d1411ad50be56a5077c/ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f3/48/47b7d25572961a48b1de3729b7a11e835b888e41e0203cca82df95d23b91/tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /home/dbt/miniconda3/envs/cosyvoice/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /home/dbt/miniconda3/envs/cosyvoice/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/46/16/7f616b55a147d9d4e9eb910a7eacde96cfa7ce3109d4c57ac32b91348ef3/namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/4b/f5/8b4ea051730c461e8957652ae58a895e5cc740b162adfe12f15d144d7c76/optree-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (397 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dbt/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dbt/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dbt/miniconda3/envs/cosyvoice/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dbt/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/dbt/.local/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/73/c6/825dab04195756cf8ff2e12698f22513b3db2f64925bdd41671bfb33aaa5/tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /home/dbt/.local/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/dbt/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/dbt/.local/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/dbt/.local/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/dbt/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Installing collected packages: namex, libclang, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, astunparse, tensorboard, keras, tensorflow\n",
      "Successfully installed astunparse-1.6.3 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.10.0 libclang-18.1.1 ml-dtypes-0.5.1 namex-0.0.9 opt-einsum-3.4.0 optree-0.15.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.1.0 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "tqdm version: 4.66.5\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 22:55:11.029139: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-25 22:55:11.063765: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748184911.086632  271508 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748184911.093563  271508 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748184911.111884  271508 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748184911.111903  271508 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748184911.111906  271508 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748184911.111908  271508 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-25 22:55:11.117351: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Relative import from the gpt_download.py contained in this folder\n",
    "\n",
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Note**\n",
    "\n",
    "- 在极少数情况下，上述代码单元可能会导致`zsh: illegal hardware instruction python`错误，这可能是由于TensorFlow安装问题\n",
    "- 有读者发现通过`conda`安装TensorFlow解决了这个问题，如[这里](https://github.com/rasbt/LLMs-from-scratch/discussions/273#discussioncomment-12367888)所述\n",
    "- 可以在[这个补充的Python设置教程](https://github.com/rasbt/LLMs-from-scratch/tree/main/setup/01_optional-python-setup-preferences#option-2-using-conda)中找到更多信息\n",
    "---\n",
    "\n",
    "- 可以如下下载124百万参数的模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Settings:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 也可以使用`model_size`参数选择\"355M\", \"774M\" 和 \"1558M\"\n",
    "- 这些不同大小的模型之间的差异总结在下面的图中\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/17.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上面，将124M GPT-2模型权重加载到Python中，但仍然需要将它们转移到`GPTModel`实例中\n",
    "- 首先，初始化一个新的GPTModel实例\n",
    "- 注意，原始GPT模型在多头注意力模块中使用偏置向量初始化查询、键和值矩阵的线性层，这并不是必需或推荐的；但是，为了能够正确加载权重，也必须通过在实现中设置`qkv_bias`为`True`来启用这些\n",
    "- 还使用了原始GPT-2模型使用的`1024`令牌上下文长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 下一个任务是将OpenAI的权重分配给`GPTModel`实例中对应的权重张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果模型正确加载，可以使用之前的generate函数来生成新文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 以上表明模型权重已经正确加载，因为模型能够生成连贯的文本；如果犯了哪怕是很小的错误，模型都将无法做到这一点\n",
    "# \n",
    "- 关于从Hugging Face Hub加载权重的另一种方式，请参见 [../02_alternative_weight_loading](../02_alternative_weight_loading)\n",
    "- 如果有兴趣了解GPT架构与Llama架构（由Meta AI开发的流行LLM）的比较，请查看 [../07_gpt_to_llama](../07_gpt_to_llama) 的额外内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结与收获\n",
    "\n",
    "- 查看 [./gpt_train.py](./gpt_train.py) 脚本，这是一个用于训练的独立脚本\n",
    "- [./gpt_generate.py](./gpt_generate.py) 脚本从OpenAI加载预训练权重，并基于提示生成文本\n",
    "- 可以在 [./exercise-solutions.ipynb](./exercise-solutions.ipynb) 中找到练习题的解答"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
