{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第五章：在无标签数据上预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib verison: 3.7.5\n",
      "numpy verison: 1.26.4\n",
      "tiktoken verison: 0.8.0\n",
      "torch verison: 2.0.1+cu118\n",
      "tensorflow is not installed\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",\n",
    "    \"numpy\",\n",
    "    \"tiktoken\",\n",
    "    \"torch\",\n",
    "    \"tensorflow\"\n",
    "]\n",
    "for p in pkgs:\n",
    "    try:\n",
    "        print(f\"{p} verison: {version(p)}\")\n",
    "    except ImportError:\n",
    "        print(f\"{p} is not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 本章节实现训练和评估一个预训练LLM的初步代码\n",
    "- 结尾也将OpenAI发布的预训练权重加载到本节实现的模型中\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/chapter-overview.webp\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 本章节覆盖的主体如下图所示：\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model--0.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 评估生成文本模型\n",
    "- 先使用之前章节中的代码初始化一个GPT模型进行一个简短的回顾\n",
    "- 然后讨论评价LLMs的基础指标/metrics\n",
    "- 最后将评价指标应用到训练和测试数据集\n",
    "\n",
    "### 5.1.1 使用GPT生成文本\n",
    "- 使用之前的代码初始化一个GPT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # 设置为评估模式，关闭dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上面使用了0.1的dropout，但现在训练LLM时不使用dropout已经相对常见\n",
    "- 现代的LLM也不在`nn.Linear`层中使用偏置向量（不同于早期的GPT模型），这是通过设置`\"qkv_bias\": False`实现的\n",
    "- 将上下文长度(`context_length`)减少到256个token，以减少训练模型的计算资源需求，而原始的124百万参数的GPT-2模型使用了1024个token\n",
    "  - 这样做是为了让更多的读者能够跟随和执行代码示例，而原始的124百万参数的GPT-2模型使用了1024个token\n",
    "  - 然而，请随意增加`context_length`到1024个token（这不需要任何代码更改）\n",
    "  - 稍后也会从预训练权重加载一个1024 `context_length`的模型\n",
    "\n",
    "- 接下来，使用上一章节的`generate_text_simple`函数生成文本\n",
    "- 此外，还定义了两个便利函数，`text_to_token_ids`和`token_ids_to_text`，用于在token和文本表示之间进行转换，本章节中会使用它们\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-process.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "\n",
    "def text_to_token_ids(text: str, tokenizer: tiktoken.Encoding) -> torch.Tensor:\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # 加一个batch维度\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids: torch.Tensor, tokenizer: tiktoken.Encoding) -> str:\n",
    "    flat = token_ids.squeeze(0)  # 移除添加的batch维度\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx = text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如上所见，模型尚未产生良好的文本，这是因为它还没有经过训练\n",
    "- 如何衡量或捕捉什么是“好的文本”，以数值形式跟踪它，以便在训练过程中测量它？\n",
    "- 下一小节介绍指标，用于计算生成输出的损失指标，我们可以使用它来衡量训练进度\n",
    "- 下一章节在微调LLMs时也会介绍其他衡量模型质量的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 计算文本生成损失：交叉熵和困惑度\n",
    "- 假设有一个`inputs`张量，其中包含了2个训练样本（行）的词元（token）ID\n",
    "- 与`inputs`相对应，`targets`包含了希望模型生成的目标词元（token）ID\n",
    "- 注意`targets`是将`inputs`向后移动1个位置得到的，正如在第2章实现数据加载器时所解释的那样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将`inputs`输入模型后，获得了2个输入样例的logits向量，每个样例包含3个tokens\n",
    "- 每个token是一个50,257维的向量，对应词汇表的大小\n",
    "- 应用softmax函数，可以将logits张量转换为相同维度的张量，其中包含概率分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)  # 词表中每个token的概率\n",
    "print(probas.shape)  # shape [batch_size, num_tokens, vocab_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 下图使用了一个非常小的词汇表进行说明，概述了如何将概率分数转换回文本，这是在上一章末尾讨论过的内容\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-to-text.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 正如在上一章中讨论的，可以应用`argmax`函数将概率分数转换为预测的token ID\n",
    "- 上面的softmax函数为每个token生成了一个50,257维的向量；`argmax`函数返回这个向量中最高概率分数的位置，即给定token的预测token ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 因为输入batch中包含两个样例，每个样例三个tokens，所以得到的token IDs也是相同形状的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: \n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Shape of token IDs: \n",
      " torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs: \\n\", token_ids)\n",
    "print(\"Shape of token IDs: \\n\", token_ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果解码上述tokens，可能发现其与希望的预测tokens非常不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这是因为模型还未训练\n",
    "- 为了训练模型，需要知道预测的结果与正确的结果还相差多远\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-index.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目标索引对应的tokens概率如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目标是最大化所有这些值，使它们接近概率1\n",
    "- 在数学优化中，最大化概率分数本身比最大化概率分数的对数更容易；这在本书的范围内不讨论，下面链接资源详细介绍了这个概念：[L8.2 Logistic Regression Loss Function](https://www.youtube.com/watch?v=GxJe0DZvydM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# 计算所有token概率的对数\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 下一步计算平均对数概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目标是使这个平均对数概率尽可能大，通过优化模型权重\n",
    "- 由于对数，最大可能值是0，而我们目前离0还很远\n",
    "\n",
    "- 在深度学习中，最大化平均对数概率是标准做法，而不是最小化平均对数概率值；本章节例子中，不是最大化-10.7722，使其接近0，而是最小化10.7722，使其接近0\n",
    "- 负的-10.7722，即10.7722，在深度学习中也称为交叉熵损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pytorch中内部实现了上述计算过程的交叉熵计算函数 `cross_entropy`\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/cross-entropy.webp?123\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在应用`cross_entropy`之前，需要检查logits和targets的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits的shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets的shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对于PyTorch中的`cross_entropy`函数，希望通过在批次维度上合并这些张量来将它们展平"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)  # 将前两维展平\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 注意targets是token IDs，也代表了logits张量中希望最大化的token索引位置\n",
    "- **PyTorch中的`cross_entropy`函数会自动在logits中应用softmax和log-概率计算，内部处理那些需要最大化的token索引位置**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一个和交叉熵损失相关的概念是LLM的困惑度\n",
    "- 困惑度是交叉熵损失的指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 困惑度通常被认为更易于解释，因为它可以被理解为模型在每个步骤中对词汇量（在上述例子中，是48,725个单词或token）的不确定性\n",
    "- 换句话说，困惑度提供了一个衡量模型预测的概率分布与数据集中单词实际分布之间匹配程度的指标\n",
    "- 类似地，损失值越低，模型预测越接近实际分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 计算训练集和验证机的损失\n",
    "- 使用一个相对较小的数据集来训练LLM（实际上，只有一篇短故事）\n",
    "- 原因如下：\n",
    "  - 可以在没有合适GPU的笔记本电脑上几分钟内运行代码示例\n",
    "  - 训练相对较快（几分钟而不是几周），这对于教育目的非常有用\n",
    "  - 使用的是公共领域的文本，可以在不违反任何使用权利或增加仓库大小的情况下包含在GitHub仓库中\n",
    "\n",
    "\n",
    "- 例如，Llama 2 7B在A100 GPU上训练2万亿个token需要184,320个GPU小时\n",
    "  - 截至撰写本文时，8xA100云服务器在AWS上的每小时成本约为30美元\n",
    "  - 因此，通过一个粗略的计算，训练这个LLM将花费184,320 / 8 * 30 = 690,000美元\n",
    " \n",
    "- 下面，使用的是第2章中使用的相同数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过打印以及在文本的前后各100个字符作为一个快速检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 100 characters:  I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n",
      "Last 100 characters:   it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "print(\"First 100 characters: \", text_data[:100])\n",
    "print(\"Last 100 characters: \", text_data[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5,145个token，文本非常短，不足以训练一个LLM，但再次强调，这是为了教育目的（稍后也会加载预训练权重）\n",
    "\n",
    "- 接下来，将数据集分为训练集和验证集，并使用第2章中的数据加载器准备LLM训练的批次\n",
    "- 为了可视化目的，下面的图假设`max_length=6`，但对于训练加载器，将`max_length`设置为LLM支持的上下文长度\n",
    "- 下面的图只显示输入token，以便于简化\n",
    "    - 因为训练LLM来预测文本中的下一个词，所以目标看起来与这些输入相同，只是目标向右移动了一个位置\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/batching.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "# 训练/验证集的划分\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(train_data,\n",
    "                                    batch_size=2,\n",
    "                                    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "                                    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "                                    drop_last=True,\n",
    "                                    shuffle=True,\n",
    "                                    num_workers=0)\n",
    "\n",
    "val_loader = create_dataloader_v1(val_data,\n",
    "                                  batch_size=2,\n",
    "                                  max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "                                  stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "                                  drop_last=False,\n",
    "                                  shuffle=False,\n",
    "                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用相对较小的批量大小来减少计算资源需求，因为数据集本身很小\n",
    "- Llama 2 7B训练时使用的批量大小为1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 以下是一个可选的检查，确保数据正确加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 另一个可选的检查是确认token大小在预期的范围内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 接下来，实现一个函数来计算给定批次的交叉熵损失\n",
    "- 此外，实现一个函数来计算数据加载器中用户指定数量的批次的损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch: torch.Tensor, target_batch: torch.Tensor,\n",
    "                    model: torch.nn.Module, device: torch.device) -> torch.Tensor:\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader: torch.utils.data.DataLoader, model: torch.nn.Module,\n",
    "                     device: torch.device, num_batches: int = None) -> float:\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # 减少批次数量以匹配数据加载器中的总批次数\n",
    "        # 如果num_batches超过了数据加载器中的批次数量\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果你有支持CUDA的GPU，LLM将使用GPU训练，而不需要任何代码更改\n",
    "- 通过`device`设置，确保数据加载到与LLM模型相同的设备上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583584255642\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 注意:\n",
    "# 取消注释以下行将允许代码在Apple Silicon芯片上运行，如果适用，这比Apple CPU（在M3 MacBook Air上测量）快约2倍。\n",
    "# 然而，结果的损失值可能略有不同。\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # 将模型移动到GPU或CPU\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # 为了可重复性，由于数据加载器中的打乱\n",
    "\n",
    "with torch.no_grad(): # 为了效率，禁用梯度跟踪，因为还没有训练\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-1.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 训练一个LLM\n",
    "- 本小节实现训练LLM的完整代码\n",
    "- 主要专注于一个简单的训练函数，如果对使用更高级技术来增强这个训练函数感兴趣，比如学习率预热、余弦退火和梯度裁剪，请参考[Appendix D](../../appendix-D/01_main-chapter-code)\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/train-steps.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.optimizer import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader,\n",
    "                   device: torch.device, eval_iter: int) -> Union[float, float]:\n",
    "    model.eval()  # 设置验证模式\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model: nn.Module, tokenizer: tiktoken.Encoding, device: torch.device,\n",
    "                              start_context: str) -> None:\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded, max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()\n",
    "\n",
    "\n",
    "def train_model_simple(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader,\n",
    "                       optimizer: Optimizer, device: torch.device, num_epochs: int, eval_freq: int,\n",
    "                       eval_iter: int, start_context: str, tokenizer: tiktoken.Encoding\n",
    "                       ) -> Union[List[float], List[float], List[int]]:\n",
    "    # 初始化用于跟踪损失和已见tokens数\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # 主训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 设置训练模式\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # 清除上一步的损失梯度\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # 计算损失梯度\n",
    "            optimizer.step()  # 梯度回传更新模型参数\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:  # 开始验证\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "        \n",
    "        # 在每个epoch最后预测一个输出并打印\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 现在开始训练LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.819, Val loss 9.934\n",
      "Ep 1 (Step 000005): Train loss 8.065, Val loss 8.340\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.622, Val loss 7.052\n",
      "Ep 2 (Step 000015): Train loss 6.048, Val loss 6.601\n",
      "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.591, Val loss 6.479\n",
      "Ep 3 (Step 000025): Train loss 5.553, Val loss 6.413\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "Ep 4 (Step 000030): Train loss 5.177, Val loss 6.367\n",
      "Ep 4 (Step 000035): Train loss 4.987, Val loss 6.379\n",
      "Every effort moves you a a, and a a, and the a, and a. Gisburn, and a, and the of the of the of the a. I had the a, and a. I had the of the a of the of the of\n",
      "Ep 5 (Step 000040): Train loss 4.351, Val loss 6.276\n",
      "Every effort moves you, I had been, I had been, I had been a of the of the, I had been, I had been, I had been the of the of the picture, as of the honour of the of the picture of the of the of\n",
      "Ep 6 (Step 000045): Train loss 4.074, Val loss 6.268\n",
      "Ep 6 (Step 000050): Train loss 3.596, Val loss 6.216\n",
      "Every effort moves you know the                                                \n",
      "Ep 7 (Step 000055): Train loss 3.632, Val loss 6.195\n",
      "Ep 7 (Step 000060): Train loss 2.829, Val loss 6.155\n",
      "Every effort moves you know the picture to see the picture.                                          \n",
      "Ep 8 (Step 000065): Train loss 2.407, Val loss 6.140\n",
      "Ep 8 (Step 000070): Train loss 2.048, Val loss 6.190\n",
      "Every effort moves you know,\" was not that, one of the deep arm-chairs forward. \"There: \"Yes, with the fact, as he had a smile behind his painting. It was his pictures--the, the donkey. \"There were, I had\n",
      "Ep 9 (Step 000075): Train loss 1.674, Val loss 6.208\n",
      "Ep 9 (Step 000080): Train loss 1.329, Val loss 6.259\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on the last word.    \"!  \"Oh, I felt him back his head to the donkey--and I saw that, and down the room, I had\n",
      "Ep 10 (Step 000085): Train loss 1.021, Val loss 6.299\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  \"I didn't dabble back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Training completed in 0.23 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 注意在不同的计算机上可能会得到略有不同的损失值，如果它们大致相似（训练损失低于1，验证损失低于7），则没有必要担心\n",
    "- 小的差异通常可能是由于不同的GPU硬件和CUDA版本，或者较新PyTorch版本中的微小变化导致的\n",
    "- 即使在CPU上运行这个示例，也可能会观察到轻微的差异；可能导致差异的一个原因是nn.Dropout在不同操作系统上的行为不同，这取决于PyTorch的编译方式，正如[here on the PyTorch issue tracker](https://github.com/pytorch/pytorch/issues/121595)中讨论的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABXCUlEQVR4nO3dd3xTVRvA8V+StumedAItq3RJ2SDUAVIpiAgI4uBFcMvGgciLIrgQREQEcb2CC1FkqqyyN5RRZimbMjqYXdCVnPePQEpYUmhJWp7v55NPk3vPvffJaZsn595zz9EopRRCCCGEsElaawcghBBCiOuTRC2EEELYMEnUQgghhA2TRC2EEELYMEnUQgghhA2TRC2EEELYMEnUQgghhA2TRC2EEELYMEnUQgghhA2TRC1EBXD48GE0Gg2JiYnWDkUIUcokUQthIzQazQ0fw4cPt3aIQggrsLN2AEIIk9TUVPPz33//nWHDhpGcnGxe5urqao2whBBWJi1qIWxEQECA+eHh4YFGozG/9vPzY+zYsVSpUgW9Xk+9evVYsGDBdfdlMBh4/vnnCQ8PJyUlBYA5c+bQoEEDHB0dqVGjBiNGjKCoqMi8jUaj4fvvv6dTp044OzsTGhrK3LlzzevPnj1Lt27d8PX1xcnJidDQUCZPnnzdGP7880/q1KmDk5MTPj4+xMbGkpuba17//fffExERgaOjI+Hh4Xz11VcW2x89epSuXbvi6emJt7c3HTp04PDhw+b1PXv2pGPHjowZM4bAwEB8fHzo06cPhYWFN13nQpQLSghhcyZPnqw8PDzMr8eOHavc3d3Vb7/9pvbs2aPeeustZW9vr/bu3auUUurQoUMKUFu3blV5eXmqU6dOqn79+iojI0MppdTKlSuVu7u7mjJlijpw4IBatGiRqlatmho+fLj5GICqUqWKmjp1qtq3b5/q37+/cnV1VadPn1ZKKdWnTx9Vr149lZCQoA4dOqTi4+PV3Llzrxn/iRMnlJ2dnRo7dqw6dOiQ2r59u5o4caLKzs5WSin1yy+/qMDAQDVjxgx18OBBNWPGDOXt7a2mTJmilFKqoKBARUREqOeff15t375d7d69Wz3zzDMqLCxM5efnK6WU6tGjh3J3d1evvvqqSkpKUn/99ZdydnZW3377ben+MoSwMknUQtigKxN1UFCQ+uijjyzKNG7cWPXu3VspVZyoV61apVq1aqXuu+8+de7cOXPZVq1aqY8//thi+59//lkFBgaaXwPqnXfeMb/OyclRgJo/f75SSqn27dur55577qbi37x5swLU4cOHr7m+Zs2aaurUqRbLPvjgA9WsWTNzbGFhYcpoNJrX5+fnKycnJ7Vw4UKllClRh4SEqKKiInOZJ554Qj355JM3FaMQ5YVcoxbCxmVlZXHixAliYmIslsfExLBt2zaLZU8//TRVqlRh6dKlODk5mZdv27aNNWvW8NFHH5mXGQwG8vLyOH/+PM7OzgBER0eb17u4uODu7k5GRgYAvXr1onPnzmzZsoXWrVvTsWNHmjdvfs2Y69atS6tWrahTpw5xcXG0bt2aLl264OXlRW5uLgcOHOCFF17gpZdeMm9TVFSEh4eHOd79+/fj5uZmsd+8vDwOHDhgfh0VFYVOpzO/DgwMZMeOHTeoTSHKH0nUQlQgjzzyCL/88gvr1q3joYceMi/PyclhxIgRPP7441dt4+joaH5ub29vsU6j0WA0GgFo27YtR44cYd68ecTHx9OqVSv69OnDmDFjrtqnTqcjPj6etWvXsmjRIr788kuGDh3Khg0bzF8KvvvuO5o2bXrVdpfibdiwIb/++utV+/b19b2peIWoKCRRC2Hj3N3dCQoKYs2aNTz44IPm5WvWrKFJkyYWZXv16sU999zDY489xj///GMu36BBA5KTk6lVq9ZtxeLr60uPHj3o0aMH999/P4MGDbpmogZT0oyJiSEmJoZhw4YREhLCrFmzeP311wkKCuLgwYN069btmts2aNCA33//HT8/P9zd3W8rZiHKO0nUQpQDgwYN4r333qNmzZrUq1ePyZMnk5iYeM0WZ79+/TAYDDz66KPMnz+f++67j2HDhvHoo48SHBxMly5d0Gq1bNu2jZ07d/Lhhx/eVAzDhg2jYcOGREVFkZ+fz99//01ERMQ1y27YsIElS5bQunVr/Pz82LBhAydPnjSXHzFiBP3798fDw4M2bdqQn5/Ppk2bOHv2LK+//jrdunXj008/pUOHDrz//vtUqVKFI0eOMHPmTN566y2qVKly65UpRDkjiVqIcqB///5kZmbyxhtvkJGRQWRkJHPnziU0NPSa5QcOHIjRaOSRRx5hwYIFxMXF8ffff/P+++8zatQo7O3tCQ8P58UXX7zpGBwcHBgyZAiHDx/GycmJ+++/n2nTpl2zrLu7OytXrmTcuHFkZWUREhLCZ599Rtu2bQF48cUXcXZ25tNPP2XQoEG4uLhQp04dBg4cCICzszMrV65k8ODBPP7442RnZ1O5cmVatWolLWxx19EopZS1gxBCCCHEtcmAJ0IIIYQNk0QthBBC2DBJ1EIIIYQNk0QthBBC2DBJ1EIIIYQNk0QthBBC2DBJ1NcxceJEqlWrhqOjI02bNmXjxo3WDskmrFy5kvbt2xMUFIRGo2H27NkW65VSDBs2jMDAQJycnIiNjWXfvn0WZc6cOUO3bt1wd3fH09OTF154gZycHIsy27dv5/7778fR0ZGqVasyevToq2KZPn064eHhODo6UqdOHebNm1fq7/dOGjlyJI0bN8bNzQ0/Pz86duxoMR81mMa67tOnDz4+Pri6utK5c2fS09MtyqSkpNCuXTucnZ3x8/Nj0KBBFtNZAixfvpwGDRqg1+upVasWU6ZMuSqeivg/MGnSJKKjo3F3d8fd3Z1mzZoxf/5883qp39L1ySefoNFozPfHg9TxLbHypCA2adq0acrBwUH98MMPateuXeqll15Snp6eKj093dqhWd28efPU0KFD1cyZMxWgZs2aZbH+k08+UR4eHmr27Nlq27Zt6rHHHlPVq1dXFy5cMJdp06aNqlu3rlq/fr1atWqVqlWrlnr66afN6zMzM5W/v7/q1q2b2rlzp/rtt9+Uk5OT+uabb8xl1qxZo3Q6nRo9erTavXu3euedd5S9vb3asWNHmddBWYmLi1OTJ09WO3fuVImJieqRRx5RwcHBKicnx1zm1VdfVVWrVlVLlixRmzZtUvfee69q3ry5eX1RUZG65557VGxsrNq6dauaN2+eqlSpkhoyZIi5zMGDB5Wzs7N6/fXX1e7du9WXX36pdDqdWrBggblMRf0fmDt3rvrnn3/U3r17VXJysvrvf/+r7O3t1c6dO5VSUr+laePGjapatWoqOjpaDRgwwLxc6rjkJFFfQ5MmTVSfPn3Mrw0GgwoKClIjR460YlS258pEbTQaVUBAgPr000/Ny86dO6f0er367bfflFJK7d69WwEqISHBXGb+/PlKo9Go48ePK6WU+uqrr5SXl5d53mGllBo8eLAKCwszv+7atatq166dRTxNmzZVr7zySqm+R2vKyMhQgFqxYoVSylSX9vb2avr06eYySUlJClDr1q1TSpm+SGm1WpWWlmYuM2nSJOXu7m6uz7feektFRUVZHOvJJ59UcXFx5td30/+Al5eX+v7776V+S1F2drYKDQ1V8fHx6sEHHzQnaqnjWyOnvq9QUFDA5s2biY2NNS/TarXExsaybt06K0Zm+w4dOkRaWppF3Xl4eNC0aVNz3a1btw5PT08aNWpkLhMbG4tWq2XDhg3mMg888AAODg7mMnFxcSQnJ3P27FlzmcuPc6lMRfodZWZmAuDt7Q3A5s2bKSwstHjf4eHhBAcHW9RvnTp18Pf3N5eJi4sjKyuLXbt2mcvcqO7ulv8Bg8HAtGnTyM3NpVmzZlK/pahPnz60a9fuqnqQOr41Mtb3FU6dOoXBYLD4IwHw9/dnz549VoqqfEhLSwO4Zt1dWpeWloafn5/Fejs7O7y9vS3KVK9e/ap9XFrn5eVFWlraDY9T3hmNRgYOHEhMTAz33HMPYHrvDg4OeHp6WpS9sn6vVS+X1t2oTFZWFhcuXODs2bMV+n9gx44dNGvWjLy8PFxdXZk1axaRkZEkJiZK/ZaCadOmsWXLFhISEq5aJ3/Dt0YStRA2qE+fPuzcuZPVq1dbO5QKJywsjMTERDIzM/nzzz/p0aMHK1assHZYFcLRo0cZMGAA8fHxFvOci9sjp76vUKlSJXQ63VW9ENPT0wkICLBSVOXDpfq5Ud0FBASQkZFhsb6oqIgzZ85YlLnWPi4/xvXKVITfUd++ffn7779ZtmyZxXSOAQEBFBQUcO7cOYvyV9bvrdadu7s7Tk5OFf5/wMHBgVq1atGwYUNGjhxJ3bp1+eKLL6R+S8HmzZvJyMigQYMG2NnZYWdnx4oVKxg/fjx2dnb4+/tLHd8CSdRXcHBwoGHDhixZssS8zGg0smTJEpo1a2bFyGxf9erVCQgIsKi7rKwsNmzYYK67Zs2ace7cOTZv3mwus3TpUoxGI02bNjWXWblyJYWFheYy8fHxhIWF4eXlZS5z+XEulSnPvyOlFH379mXWrFksXbr0qtP/DRs2xN7e3uJ9Jycnk5KSYlG/O3bssPgyFB8fj7u7O5GRkeYyN6q7u+1/wGg0kp+fL/VbClq1asWOHTtITEw0Pxo1akS3bt3Mz6WOb4G1e7PZomnTpim9Xq+mTJmidu/erV5++WXl6elp0QvxbpWdna22bt2qtm7dqgA1duxYtXXrVnXkyBGllOn2LE9PTzVnzhy1fft21aFDh2venlW/fn21YcMGtXr1ahUaGmpxe9a5c+eUv7+/6t69u9q5c6eaNm2acnZ2vur2LDs7OzVmzBiVlJSk3nvvvXJ/e1avXr2Uh4eHWr58uUpNTTU/zp8/by7z6quvquDgYLV06VK1adMm1axZM9WsWTPz+ku3trRu3VolJiaqBQsWKF9f32ve2jJo0CCVlJSkJk6ceM1bWyri/8Dbb7+tVqxYoQ4dOqS2b9+u3n77baXRaNSiRYuUUlK/ZeHyXt9KSR3fCknU1/Hll1+q4OBg5eDgoJo0aaLWr19v7ZBswrJlyxRw1aNHjx5KKdMtWu+++67y9/dXer1etWrVSiUnJ1vs4/Tp0+rpp59Wrq6uyt3dXT333HMqOzvbosy2bdvUfffdp/R6vapcubL65JNProrljz/+ULVr11YODg4qKipK/fPPP2X2vu+Ea9UroCZPnmwuc+HCBdW7d2/l5eWlnJ2dVadOnVRqaqrFfg4fPqzatm2rnJycVKVKldQbb7yhCgsLLcosW7ZM1atXTzk4OKgaNWpYHOOSivg/8Pzzz6uQkBDl4OCgfH19VatWrcxJWimp37JwZaKWOi45jVJKWactL4QQQoh/I9eohRBCCBsmiVoIIYSwYZKohRBCCBsmiVoIIYSwYZKohRBCCBsmiVoIIYSwYZKobyA/P5/hw4eTn59v7VAqJKnfsiX1W/akjsuW1K+J3Ed9A1lZWXh4eJCZmYm7u7u1w6lwpH7LltRv2ZM6LltSvybSohZCCCFsmCRqIYQQwoZV+Pmoi4qK2Lp1K/7+/mi1Jftekp2dDcDx48fJysoqi/DualK/ZUvqt+xJHZetily/RqOR9PR06tevj53djVNxhb9GnZCQQJMmTawdhhBCCHGVjRs30rhx4xuWqfAtan9/f8BUGYGBgVaORgghhIDU1FSaNGlizlE3UuET9aXT3YGBgVSpUsXK0QghhBDFbuaSrFU7k61cuZL27dsTFBSERqNh9uzZFuuVUgwbNozAwECcnJyIjY1l37591glWCCGEsAKrJurc3Fzq1q3LxIkTr7l+9OjRjB8/nq+//poNGzbg4uJCXFwceXl5dzhSIYQQwjqseuq7bdu2tG3b9prrlFKMGzeOd955hw4dOgDw008/4e/vz+zZs3nqqafuZKhCCCGEVdjsNepDhw6RlpZGbGyseZmHhwdNmzZl3bp1103U+fn5FsPNXereL4QQN8NgMFBYWGjtMEQ5Z29vj06nK5V92WyiTktLA7iqR5y/v7953bWMHDmSESNGlGlsQoiKRylFWloa586ds3YoooLw9PQkICAAjUZzW/ux2UR9q4YMGcLrr79ufn38+HEiIyNLZ+eGIlj2EdRoATUeLJ19CiFswqUk7efnh7Oz821/uIq7l1KK8+fPk5GRAXDbtwbbbKIOCAgAID093eJNpqenU69evetup9fr0ev15telOZpNwerxOKweC4m/wqurwdWv1PYthLAeg8FgTtI+Pj7WDkdUAE5OTgBkZGTg5+d3W6fBbXas7+rVqxMQEMCSJUvMy7KystiwYQPNmjW74/GkZ+XRbn0ke1VVyEmHmS+B0XDH4xBClL5L16SdnZ2tHImoSC79Pd1unwerJuqcnBwSExNJTEwETB3IEhMTSUlJQaPRMHDgQD788EPmzp3Ljh07ePbZZwkKCqJjx453PFZfVz1+Pp70KuhPHno4uBxWjb3jcQghyo6c7halqbT+nqyaqDdt2kT9+vWpX78+AK+//jr169dn2LBhALz11lv069ePl19+mcaNG5OTk8OCBQtwdHS847FqtRpGd6lLukMIQwueMy1c/jEcXn3HYxFCCHH3sGqibtGiBUqpqx5TpkwBTN9G3n//fdLS0sjLy2Px4sXUrl3bavFW9nRi2KORzDA+wEzjA6CM8OcLkHPSajEJIURpq1atGuPGjbvp8suXL0ej0ZR5j/kpU6bg6elZpsewRTZ7jdpWPdGoCg+F+zG0oCcpuqqQkwazXgaj0dqhCSHuMhqN5oaP4cOH39J+ExISePnll2+6fPPmzUlNTcXDw+OWjiduTBJ1CWk0Gj55vA4OTm68cL4fhVo9HFgKaz63dmhCiLtMamqq+TFu3Djc3d0tlr355pvmskopioqKbmq/vr6+JepY5+DgUCr3C4trk0R9C/zcHXm/QxT7VBXeLehhWrj0IziyzrqBCSHuKgEBAeaHh4cHGo3G/HrPnj24ubkxf/58GjZsiF6vZ/Xq1Rw4cIAOHTrg7++Pq6srjRs3ZvHixRb7vfLUt0aj4fvvv6dTp044OzsTGhrK3LlzzeuvPPV96RT1woULiYiIwNXVlTZt2pCammrepqioiP79++Pp6YmPjw+DBw+mR48eJe4sPGnSJGrWrImDgwNhYWH8/PPP5nVKKYYPH05wcDB6vZ6goCD69+9vXv/VV18RGhqKo6Mj/v7+dOnSpUTHvlMkUd+ix+oG8UidAKYVPchi+xagDPDn85B72tqhCSFKgVKK8wVFVnkopUrtfbz99tt88sknJCUlER0dTU5ODo888ghLlixh69attGnThvbt25OSknLD/YwYMYKuXbuyfft2HnnkEbp168aZM2euW/78+fOMGTOGn3/+mZUrV5KSkmLRwh81ahS//vorkydPZs2aNWRlZV01g+K/mTVrFgMGDOCNN95g586dvPLKKzz33HMsW7YMgBkzZvD555/zzTffsG/fPmbPnk2dOnUAU2fm/v378/7775OcnMyCBQt44IEHSnT8O8VmBzyxdRqNhg863MPGQ2fon/0sqzwP4ZN9BP4eAE/+Yu3whBC36UKhgchhC61y7N3vx+HsUDofz++//z4PP/yw+bW3tzd169Y1v/7ggw+YNWsWc+fOpW/fvtfdT8+ePXn66acB+Pjjjxk/fjwbN26kTZs21yxfWFjI119/Tc2aNQHo27cv77//vnn9l19+yZAhQ+jUqRMAEyZMYN68eSV6b2PGjKFnz5707t0bMN05tH79esaMGUPLli1JSUkhICCA2NhY7O3tCQ4OpkmTJgCkpKTg4uLCo48+ipubGyEhIeY7kGyNtKhvg4+rno861eE8jnTP6sV570h48G1rhyWEEGaNGjWyeJ2Tk8Obb75JREQEnp6euLq6kpSU9K8t6ujoaPNzFxcX3N3dzUNkXouzs7M5SYNpGM1L5TMzM0lPTzcnTQCdTkfDhg1L9N6SkpKIiYmxWBYTE0NSUhIATzzxBBcuXKBGjRq89NJLzJo1y3yd/uGHHyYkJIQaNWrQvXt3fv31V86fP1+i498p0qK+TXFRATxevzIzt8Kj+R/zj3cETtYOSghx25zsdex+P85qxy4tLi4uFq/ffPNN4uPjGTNmDLVq1cLJyYkuXbpQUFBww/3Y29tbvNZoNBhvcLfLtcqX5in9m1G1alWSk5NZvHgx8fHx9O7dm08//ZQVK1bg5ubGli1bWL58OYsWLWLYsGEMHz6chIQEm7sFTFrUpeC99lEEuDty8PR5Ri/cY1p4bDOcv/71GyGEbdNoNDg72FnlUZa9p9esWUPPnj3p1KkTderUISAggMOHD5fZ8a7Fw8MDf39/EhISzMsMBgNbtmwp0X4iIiJYs2aNxbI1a9ZYTMTk5ORE+/btGT9+PMuXL2fdunXs2LEDADs7O2JjYxk9ejTbt2/n8OHDLF269DbeWdmQFnUp8HC255POdeg5OYHJaw7TTb+GWuuHQK2H4enfQG5ZEELYiNDQUGbOnEn79u3RaDS8++67N2wZl5V+/foxcuRIatWqRXh4OF9++SVnz54t0ZeUQYMG0bVrV+rXr09sbCx//fUXM2fONPdinzJlCgaDgaZNm+Ls7Mwvv/yCk5MTISEh/P333xw8eJAHHngALy8v5s2bh9FoJCwsrKze8i2TFnUpaRHmx9NNggH4aLMWpdGCnR6K8qwcmRBCFBs7dixeXl40b96c9u3bExcXR4MGDe54HIMHD+bpp5/m2WefpVmzZri6uhIXF1eiIaI7duzIF198wZgxY4iKiuKbb75h8uTJtGjRAjDNB/3dd98RExNDdHQ0ixcv5q+//sLHxwdPT09mzpzJQw89REREBF9//TW//fYbUVFRZfSOb51G3emLBnfYsWPHqFq1KkePHqVKlSpleqyc/CLajFvJsbMXGBBdxGtPPyataSHKgby8PA4dOkT16tWtMpeAAKPRSEREBF27duWDDz6wdjil4kZ/VyXJTdKiLkWuejs+7WK67eGL7XYs33txDHCloPCCFSMTQgjbcuTIEb777jv27t3Ljh076NWrF4cOHeKZZ56xdmg2RxJ1KWtW04fnYqoB8PaMHWSePQ1/PAszXjQlbCGEEGi1WqZMmULjxo2JiYlhx44dLF68mIiICGuHZnOkM1kZeCsunBXJJzl4Kpfv5y7hjZQFYCiADd/Ava9aOzwhhLC6qlWrXtVjW1ybtKjLgJODjjFd66LVwJdJLiTVecu0YtE7cLxktx8IIYS4u0miLiMNgr145UHTqDzdd9QlP7QdGAthek+4cM6qsQkhhCg/JFGXoYGxoYT5u3Eqt5AhRa+gPIPh3BGY20+uVwshhLgpkqjLkN5Ox2dd62Kn1TAzKYeVdT8FrT0kzYWE760dnhBCiHJAEnUZu6eyB/0eCgWg/0ot2Q+8a1qx8L9wItF6gQkhhCgXJFHfAb1b1qROZQ8yLxQy4FAzVNgjpl7g03tCXpa1wxNCCGHDJFHfAfY6LZ91rYuDTsvS5JPMCR4KHlXh7CH4a4BcrxZCWFWLFi0YOHCg+XW1atUYN27cDbfRaDTMnj37to9dWvu5keHDh1OvXr0yPUZZkkR9h9T2d+ON1rUBeGfRcTLiJoHWDnbNhM2TrRydEKI8at++PW3atLnmulWrVqHRaNi+fXuJ95uQkMDLL798u+FZuF6yTE1NpW3btqV6rIpGEvUd9OL9NWgY4kVOfhED19hjfOg904rVn0NRvnWDE0KUOy+88ALx8fEcO3bsqnWTJ0+mUaNGREdHl3i/vr6+ODs7l0aI/yogIAC9Xn9HjlVeSaK+g3RaDWOeqIujvZa1B07zi/ZRePBteGGxaaYtIYQogUcffRRfX1+mTJlisTwnJ4fp06fzwgsvcPr0aZ5++mkqV66Ms7MzderU4bfffrvhfq889b1v3z4eeOABHB0diYyMJD4+/qptBg8eTO3atXF2dqZGjRq8++67FBYWAqbpJkeMGMG2bdvQaDRoNBpzzFee+t6xYwcPPfQQTk5O+Pj48PLLL5OTk2Ne37NnTzp27MiYMWMIDAzEx8eHPn36mI91M4xGI++//z5VqlRBr9dTr149FixYYF5fUFBA3759CQwMxNHRkZCQEEaOHAmAUorhw4cTHByMXq8nKCiI/v373/Sxb4UMIXqHVa/kwpC2Ebw3dxcj5+/lgQH9qebmYu2whBDXU5Bb8m10etBd/Hg1FIEhHzRasHf69/063PzngZ2dHc8++yxTpkxh6NCh5rmcp0+fjsFg4OmnnyYnJ4eGDRsyePBg3N3d+eeff+jevTs1a9akSZMm/3oMo9HI448/jr+/Pxs2bCAzM9PievYlbm5uTJkyhaCgIHbs2MFLL72Em5sbb731Fk8++SQ7d+5kwYIF5rmiPTw8rtpHbm4ucXFxNGvWjISEBDIyMnjxxRfp27evxZeRZcuWERgYyLJly9i/fz9PPvkk9erV46WXXrqpevviiy/47LPP+Oabb6hfvz4//PADjz32GLt27SI0NJTx48czd+5c/vjjD4KDgzl69ChHjx4FYMaMGXz++edMmzaNqKgo0tLS2LZt200d91ZJoraC7veGsGBnGusOnubN6dv4/ZVm6LQaSPwNTmyFtqNkekwhbMXHQSXf5okpENXJ9HzPX6Y7PELug+f+KS4zrg6cP331tsMzS3So559/nk8//ZQVK1aY52GePHkynTt3xsPDAw8PD958801z+X79+rFw4UL++OOPm0rUixcvZs+ePSxcuJCgIFNdfPzxx1ddV37nnXfMz6tVq8abb77JtGnTeOutt3BycsLV1RU7OzsCAgKue6ypU6eSl5fHTz/9hIuL6QvLhAkTaN++PaNGjcLf3x8ALy8vJkyYgE6nIzw8nHbt2rFkyZKbTtRjxoxh8ODBPPXUUwCMGjWKZcuWMW7cOCZOnEhKSgqhoaHcd999aDQaQkJCzNumpKQQEBBAbGws9vb2BAcH31Q93g459W0FWq2G0V2icdXbsenIWf63+iCcPgBzesPGbyDpL2uHKIQoJ8LDw2nevDk//PADAPv372fVqlW88MILABgMBj744APq1KmDt7c3rq6uLFy4kJSUlJvaf1JSElWrVjUnaYBmzZpdVe73338nJiaGgIAAXF1deeedd276GJcfq27duuYkDRATE4PRaCQ5Odm8LCoqCp1OZ34dGBhIRkbGTR0jKyuLEydOEBMTY7E8JiaGpKQkwHR6PTExkbCwMPr378+iRYvM5Z544gkuXLhAjRo1eOmll5g1axZFRUUlep8lZdMtaoPBwPDhw/nll19IS0sjKCiInj178s4775hP8ZRXVb2deffRCAbP2MGYRXtpGXYfoY+MgTMHIfxRa4cnhLjkvydKvo3usj4n4e1N+9Bc0S4auOP24rrMCy+8QL9+/Zg4cSKTJ0+mZs2aPPjggwB8+umnfPHFF4wbN446derg4uLCwIEDKSgoKLXjr1u3jm7dujFixAji4uLw8PBg2rRpfPbZZ6V2jMvZ29tbvNZoNBiNxlLbf4MGDTh06BDz589n8eLFdO3aldjYWP7880+qVq1KcnIyixcvJj4+nt69e5vPaFwZV2mx6Rb1qFGjmDRpEhMmTCApKYlRo0YxevRovvzyS2uHViq6NqpKyzBfCoqMvDF9G4UNnoO4j0Br078WIe4uDi4lf+guawPp7EzLLr8+faP93oKuXbui1WqZOnUqP/30E88//7y5MbNmzRo6dOjAf/7zH+rWrUuNGjXYu3fvTe87IiKCo0ePkpqaal62fv16izJr164lJCSEoUOH0qhRI0JDQzly5Ijl23VwwGAw/Ouxtm3bRm5u8fX7NWvWoNVqCQsLu+mYb8Td3Z2goKCrpthcs2YNkZGRFuWefPJJvvvuO37//XdmzJjBmTNnAHBycqJ9+/aMHz+e5cuXs27dOnbsKL0vXley6Yywdu1aOnToQLt27ahWrRpdunShdevWbNy40dqhlQqNRsMnnaPxcLJn+7FMJi7bX7yyKB+mPwfJ860XoBCiXHB1deXJJ59kyJAhpKam0rNnT/O60NBQ4uPjWbt2LUlJSbzyyiukp6ff9L5jY2OpXbs2PXr0YNu2baxatYqhQ4dalAkNDSUlJYVp06Zx4MABxo8fz6xZsyzKVKtWjUOHDpGYmMipU6fIz7/6ltRu3brh6OhIjx492LlzJ8uWLaNfv350797dfH26NAwaNIhRo0bx+++/k5yczNtvv01iYiIDBgwAYOzYsfz222/s2bOHvXv3Mn36dAICAvD09GTKlCn873//Y+fOnRw8eJBffvkFJycni+vYpc2mE3Xz5s1ZsmSJ+dvftm3bWL16dYW6Od7f3ZH3O0QB8MWSfSzeffEfaMM3psFQpveEwzK5uhDixl544QXOnj1LXFycxfXkd955hwYNGhAXF0eLFi0ICAigY8eON71frVbLrFmzuHDhAk2aNOHFF1/ko48+sijz2GOP8dprr9G3b1/q1avH2rVreffddy3KdO7cmTZt2tCyZUt8fX2veYuYs7MzCxcu5MyZMzRu3JguXbrQqlUrJkyYULLK+Bf9+/fn9ddf54033qBOnTosWLCAuXPnEhpqmpfBzc2N0aNH06hRIxo3bszhw4eZN28eWq0WT09PvvvuO2JiYoiOjmbx4sX89ddf+Pj4lGqMl9MoZbvjVxqNRv773/8yevRodDodBoOBjz76iCFDhlx3m/z8fItvasePHycyMpKjR49SpUqVOxH2LRk6awe/bkjBxUHHrD4x1K7kCL93h73zQe8OPf+GwLrWDlOICikvL49Dhw5RvXp1HB0drR2OqCBu9Hd17NgxqlatelO5yaZb1H/88Qe//vorU6dOZcuWLfz444+MGTOGH3/88brbjBw50nxLgoeHh8U1B1s2/LEo7q3hTW6BgRd/3MTZPAVPTIaQGMjPgl86m3qGCyGEuKvYdKIeNGgQb7/9Nk899RR16tShe/fuvPbaa+YRYq5lyJAhZGZmmh+7d+++gxHfOnudlq+6NaSqtxMpZ87T69fNFGr18PRvEBANuSfhp46QdQs9UIUQQpRbNp2oz58/j/aKHtA6ne6G3fD1ej3u7u7mh5ubW1mHWWq8XRz4X4/GuDjoWH/wDCP+2gWOHvCfmeBdEzJT4OdOcP6MtUMVQghxh9h0om7fvj0fffQR//zzD4cPH2bWrFmMHTuWTp06WTu0MlPb340vnqqPRgO/rE/h5/VHwNUXnp0NbkFwcg/8+gTk5/zrvoQQQpR/Np2ov/zyS7p06ULv3r2JiIjgzTff5JVXXuGDDz6wdmhlKjbSn0FxpnsGh8/dxdoDp8AzGLrPAicvOL4Jfv+PzLglhBB3AZtO1G5ubowbN44jR45w4cIFDhw4wIcffoiDg4O1QytzvR6sScd6QRiMit6/buHI6VzwC4duM8DeBQ4ug5kvg/HGAwgIIW5eaY5uJURp/T3Z9BCid7NLg6EcOpXLtmOZvPjjJmb2bo5blYbw1K+m09+7Z8OiIGhz/c51Qoh/5+DggFar5cSJE/j6+uLg4FDuhykW1qOUoqCggJMnT6LVam+7cSmJ2oY52uv49tlGPDZhNfsychg4LZFvn22ErmZL6Pw9zHsT6nSxdphClHtarZbq1auTmprKiRNyZ4UoHc7OzgQHB1/VKbqkJFHbOH93R77t3oiu36xjyZ4MPl2YzNttwyGqI9RqBfry06tdCFvm4OBAcHAwRUVF/zomtRD/RqfTYWdnVypnZiRRlwN1q3oyuks0A6Yl8vWKA4QFuNKpfhXLJH18s2lAlOiu1gtUiHJOo9Fgb29fZrMgCXErJFGXEx3qVSY5LZuvlh9g8IwdVPNxoX6wl2nlqf0wpT0U5YGrH9RoYdVYhRBClB6b7vUtLL3ZOoyHI/0pKDLyys+bScvMM63wqQlRnaDafVC5oXWDFEIIUaokUZcjWq2Gz5+sR5i/GxnZ+bz88ybyCg2g0UD7L6DbdLlmLYQQFYwk6nLGVW/H9z0a4e3iwPZjmQz6cztKKdPk9HZ6UyGlYN1EOLXPusEKIYS4bZKoy6Gq3s581a0BdloNf207wVfLr5hVa8M3sPC/pnHBM49bJ0ghhBClQhJ1OXVvDR/e73APAJ8uTGbRrrTilXW6gE8tyDxqSta5p60UpRBCiNsliboce6ZpMD2ahQAw8PdE9qRlmVa4VILus8G9MpxKhl+7mHqGCyGEKHckUZdz7z4aSUwtH84XGHjxx02czrk4UYdn1YuTeHjDiS0woSH8Lw62/AT52dYNWgghxE2TRF3O2em0THymAdV8nDl29gK9ft1CQdHFgeB9w6Dn3xDaGjRaOLoe5vaDMbVh1qtwaBXIJARCCGHTJFFXAJ7ODnzfoxFuejs2HjrDe3N3mXqCA/hHmW7bem03xA4Hn1AoPA/bfoMfH4Uv60PSX1aNXwghxPVJoq4gavm5Mf7p+mg08NvGFH5ad8SygHsg3Pca9E2AF+KhQQ9wcIOzh8HeubjchbNQeOGOxi6EEOL6JFFXIC3D/RjSNhyA9//ezep9p64upNFA1Sbw2Hh4cy90/p/lkKOrPoMxYbDphzsTtBBCiBuSRF3BvHR/DR5vUBmDUdH7180cOpV7/cIOzqZbubS64mUp6yE/E1wDipflnoLs9LILWgghxHVJoq5gNBoNH3eqQ/1gT7LyinjxxwSy8gpvfgfPL4Ief0How8XLNnwNYyNg6lOm69lFBaUfuBBCiGuSRF0BOdrr+KZ7QwI9HDlwMpd+U7dSaLjJ3t1aLVR/AHSXTfN3ah8oA+ydD7//B8aGw4IhkLazbN6AEEIIM40ydw+umI4dO0bVqlU5evQoVapUsXY4d9TO45l0+XoteYVGKns68WqLmjzRsAqO9rp/3/hKJ5Mh8VfYNg1yLjsN7lHVNLCKeyC4BYJbALgFQUhz8Khcem9GCCEqkJLkJknUFdySpHQGz9jOqRzT6Wo/Nz0vP1CDZ5oG4+xwC9ORG4rgwBLY+jMkLwDjdU6rP/krRDxqep70NywZAbUehjYfF5dJXgDO3qYE7+oPdg4lj0cIIcqhkuSmW/ikFuVJqwh/Vg9+iN8TjvL1igOkZubx4T9JfLX8AC/cV53uzUJwd7T/9x1dorOD2nGmx/kzptPi2ScgOw2yUyEr1fTTu3rxNueOwKm9EFCneJnRANOeBnXZKXnnSpe1ygPAyQv07qapO/Vu4OgOVZuCq5+pfFE+GItMt5dpNLdXUUIIYaOkRX0XKSgyMnPLMSatOMCR0+cBcHO0o2fzajwXUx1vlzJq0Wanw8k9pkQbVN+07MI5mNrVlNSz08Bwkx3Uuv1Z3NFt6y8wp49p5LVu04vL/PgY6ByKE7zezTLh611Nyd38cAKPKqb4wDRNqCR+IUQZkha1uCYHOy1PNQmmS8Mq/LMjlQlL97MvI4cvl+7n+1WH+M+9wbx0fw383B1L98Bu/qbH5Zw84YVFpudKmVrn2amXPdIgL9M0Lvnlj0utaSges9zBtXiZ0QCHVpQ8xi4/wD2dTc+T5sKfL5g61XWfWVzm1ydMg8FcSu7mn5c91+pMMSiD6X2FtoageqbtT+2DLT+azho061O83yUfQO5J0zZGo+ksgzJc3M/F52A6w+Dia3oE31v8pcdoBJTlbXZCiApDEvVdyE6npUO9yrSPDmLR7jQmLNvPzuNZfLfqED+uO8KTjaryyoM1qOLl/O87Kw0aDbj4mB4B99z8dk1fhQbPmk5/X+7JX0xJPC/rYoLPujrhF12AgvOmxFt43tTivqTwwsVr71ecbDqyDgpKOKGJq19xoj6XAmu/BP86lol65ww4e6hk+33oneJEfTIJJsVApdrQd2NxmQ3fmu6Jv5TcXXxNM6u5+Jq+3MhZAyGuTynTmb6iPCjMM/3vWOnLsCTqu5hWq6HNPYHERQWwfO9JJizdz+YjZ/l5/RF+25hCp/qV6dWiJjV8Xf99Z9ag0YCDi+UyrQ4i2t/efiM7mlrTXJHIOn8PhbkXk/sFKMgtTvSXfiplmgBFqwWNzpQ8L/EMgeb9TL3iL9esD+SdM22n0V3cXnfZc61pvxfOmlreuSdNyf6S3JPAxeNebtMPpiR+LXaOxYlb737xeFqo+7RpEBwwDS+7cKipJd9hQvG2y0bCmYOm+tdoLx5Xc9nry5bbOZp+R1WbQK1Y0/ZFBXBwuWnAnZCY4i8MBbmgtTNdtpAvEeJalCr+XyvIvfjzvOn/8tLPyE6m/xkwdWQ9vhlqtYJq95mWndoP8e+a9lOUb/rSXpR/7deXf1kfuNM0K6EVSKIWaDQaWob50aK2L+sPnmHCsn2s2X+a6ZuPMWPLMdpFB9GnZU3CA9z/fWcVgb0j2AddvTysze3tt1ItaP3h1cubvHR7+612P7y5z/TBdbnoJ+DMIdPIcpcSfO4p04dZUR5kHjU9LhfSvPh5Xibs+fvqLxYHlsCxhJLFeG/v4kR9/hRMfcL0RWTY6eIyM182HU+jMyV3e2dTMrd3Mb12uNinwMHl4mUGe9MXgOiupu0NhbB6nOlLR7O+xXcRHFlrqgedvemLgNbuOs/tTZ0ldQ7g6Gm65fCSu63fglIXk1ae6TLVJZnHTX9nbgHFfTpyT5s6ixqLLj4Mlz2/zjJltPy73zTZNB1v9FNQLca0LGU9/P3aFQn5PFed6brSkNamvigAexeY7lBxcClO1IW5kDyv5HVSlF/ybUqJzSfq48ePM3jwYObPn8/58+epVasWkydPplGjRtYOrcLRaDQ0q+lDs5o+bEk5y8Sl+1myJ4O/tp3gr20neDjSn74ta1G3qqe1QxWX0+osr91fcv8b1y5fkHsxeZ+C3AzTpQClTB+egdHF5dyrwKOfW07aAqZLDlGdLl4/v7idunid/MplRXmm4wXfW7y9UhBYF3Mr/PK4wHRNPj/L9Pg3heeLE3VRHiz7sDhGLibqLT+ZZosriVqx8J8Zxa9HVjF9Eei7EbyqmZatmwjbfzedNbj0sHe8zms92DmZkn9Up+L97pplOsMQ+rDpVkWA0wdMiU+jM/1uL51d0epMXyg0uuIzNpeW2emL4wLYt9j0xazmQ8X9Q46shZ0zL7ZIc4sT36UzQpcSovnskNF01mXQ/uL9zngRUtbCEz9CVEfTskPL4c/nS1a/AI1fLP79H1hq6hsSEF2cqA0FkLH7+tvbOV72xe2yL3WXXwqr0cK0/tJlIjCN/dD+i8t+R07Fvx87/bVfW/ksj00n6rNnzxITE0PLli2ZP38+vr6+7Nu3Dy8vL2uHVuE1CPbifz0bs+tEJl8tO8C8nanE704nfnc694dWom/LWjSt4WPtMMWtcLjYQvUKuXE5Fx9odI0P4Eunxm+VR2V4ZeXVy7tNv/bpzIJcy1Obl/oWGAtNH+yXaHSmWeGMBtMH6yX+UaZ7+I2FpnEAjEUXnxcWt/AuPTcUmhKEo2fx9koVJy6dvnj5uRRI3Vay916liWWiXjDE1HnylZXFiXrXTFh6jTMvN1KptmlmvEsWvWO67PHs3OJEnZEECd+VbL9X9v9wdDddCrn8Wq3eA3xqXfYlQld8tkJrd53XOsuzFPd0Nn1JrNyweL8BdaD77GucXbl4ZuVmrhfX6XL136uzNzTsWbJ6sDKbvj3r7bffZs2aNaxateqW9yG3Z5WO/Rk5fLV8P3MST2Awmv5kmlTz5tUWNXiwth867V10WlDcXZQynX0oygP3oOIEcWqf6Tr+pc5GRZc9rnx9aZlPTWj53+J9z3jRtO9HPy8ee2DLz6b+BZfuAjAWXXYXwMWflz9XBtPogL3WFO93bn/IPAYPDS1Ofse3mE75Xn754NItipeSoL2T5XN7Z9PlAFHqynxksqNHj6LRaMw737hxI1OnTiUyMpKXX3751qK+hsjISOLi4jh27BgrVqygcuXK9O7dm5deuvlrepKoS9fRM+eZtOIAf246RsHF8cMDPRzp3KAKTzSqQoiPy7/sQQghREly0y1NyvHMM8+wbNkyANLS0nj44YfZuHEjQ4cO5f3337+VXV7TwYMHmTRpEqGhoSxcuJBevXrRv39/fvzxx+tuk5+fT1ZWlvmRnV3C22nEDVX1dubjTnVY+VZLXryvOp7O9qRm5jFh2X4e/HQ5T327jplbjnGhwGDtUIUQokK4pRa1l5cX69evJywsjPHjx/P777+zZs0aFi1axKuvvsrBgwdLJTgHBwcaNWrE2rVrzcv69+9PQkIC69atu+Y2w4cPZ8SIEVctlxZ12cgrNLA4KZ0/Nh1j1b6TXPprctPb0b5eEE82qkp0FQ80d1OPWSGE+Bdl3qIuLCxErzd1qli8eDGPPfYYAOHh4aSmpt7KLq8pMDCQyMhIi2URERGkpKRcd5shQ4aQmZlpfuzefYNeg+K2OdrreDQ6iJ+eb8LqwQ/x+sO1qeLlRHZ+EVM3pNBh4hrajFvF96sOcjrHerc3CCFEeXVLiToqKoqvv/6aVatWER8fT5s2pvtLT5w4gY9P6fUEjomJITk52WLZ3r17CQm5fm9VvV6Pu7u7+eHm5lZq8Ygbq+zpRP9Woawc1JKpLzalY70g9HZaktOz+fCfJO4duYRev2xm2Z4Mc4c0IYQQN3ZL3flGjRpFp06d+PTTT+nRowd169YFYO7cuTRp0qTUgnvttddo3rw5H3/8MV27dmXjxo18++23fPvtt6V2DFH6tFoNzWtVonmtSoy4UMjcbSeYvuko249lMn9nGvN3phHg7kjnhpV5omFVqlWSDmhCCHE9t3x7lsFgICsry+Ke5sOHD+Ps7Iyf3zUGX7hFf//9N0OGDGHfvn1Ur16d119/XXp9l1NJqVn8sekos7ce5+z54nmsm1T35slGVWlbJ+DW5sgWQohypsxvz7pw4QJKKZydTSMWHTlyhFmzZhEREUFcXNytRV1GJFHbnvwiA0uSMvg94SgrL+uA5qq3o33dILo2qkK9qp7SAU0IUWGVeaJu3bo1jz/+OK+++irnzp0jPDwce3t7Tp06xdixY+nVq9ctB1/aJFHbthPnLjBzyzH+2HSMlDPnzctD/Vyp6euK3l6L3k6L3k6Ho73pp95Oe3H5TSyz05n34Wivw0GnRSuDswghrKzM56PesmULn3/+OQB//vkn/v7+bN26lRkzZjBs2DCbStTCtgV5OtH3oVB6t6jFhkNn+GPTUebtSGVfRg77MnLK5Jiezva0qO1LXFQAD4b5yul2IYRNu6VPqPPnz5t7Uy9atIjHH38crVbLvffey5EjR0o1QHF30GqLJwQZ0SGKFcknybxQSH6RkfwiA3mFpp/5hUbTskKDeV1+kZG8S68Lr16WV2jg8k7m584XMjvxBLMTT6C303J/qC9xUf7ERvjj5eJw/SCFEMIKbilR16pVi9mzZ9OpUycWLlzIa6+9BkBGRgbu7nfJVIiizLg72tO+7jWmmbwNRQYjeRcT/MFTuSzcmcbC3WkcPXOBxUnpLE5KR6fV0KSaN3FR/rSOCiDI06lUYxBCiFtxS9eo//zzT5555hkMBgMPPfQQ8fHxAIwcOZKVK1cyf/78Ug/0Vsk1anE9Sin2pGWzcFcaC3elk5RqOa1incoexEX5ExcVQC0/V+ncJoQoNWXemQxMY3ynpqZSt25dtFrTuCkbN27E3d2d8PDwW9llmZBELW5WyunzLNqdxsJdaWw6cpbL/zNqVHKhdVQAcVH+1K3iKR3ShBC35Y4k6ssPBthsEpRELW7Fyex8liSls3BXGmv2nzbPFAbg766ndWQAcVEBNK3hjb3ulgb4E0Lcxco8URuNRj788EM+++wzcnJMPXPd3Nx44403GDp0qLmFbQskUYvblZ1XyPLkkyzclcby5JPk5BeZ13k42dMq3I/WUf48UFt6kAshbk6Z3541dOhQ/ve///HJJ58QExMDwOrVqxk+fDh5eXl89NFHt7JbIWyS28XObe3rBpFfZGDt/tMs3JVG/O50TucWMHPrcWZuPY6jvZZ6VT2p5edKLV9Xavm5UdPPhQB3R7m+LYS4ZbfUog4KCuLrr782z5p1yZw5c+jduzfHjx8vtQBvl7SoRVkxGBVbUs5a9CC/Fle9HTV9Xajp52pO4jX9XAnxdsZOTpsLcVcq8xb1mTNnrtlhLDw8nDNnztzKLoUod3RaDY2redO4mjdD20WQnJ7NruNZHDiZw/6MHPafzOHI6fPk5Bex7Vgm245lWmxvr9NQzcfFlLwvjsRWy8+VGr4ucgpdCGF2S58GdevWZcKECYwfP95i+YQJE4iOji6VwIQoTzQaDeEB7oQHWI4jUFBk5Mjp3OLkfTGBH8jI5UKh4bojsFX2dLJI3rX9Xakf7IVOepsLcde5pUQ9evRo2rVrx+LFi2nWrBkA69at4+jRo8ybN69UAxSiPHOw0xLq70aov+W86EajIjUrrzh5Z+RwICOHAydzOJ1bwPFzFzh+7gIr9p40bxPm78aguDBaRfjJNW8h7iK3fHvWiRMnmDhxInv27AEgIiKCl19+mQ8//NCm5ouWa9SivDmbW8D+y1rgB07msPnIWbLzTL3NG4V48XbbcBpV87ZypEKIW3VH76O+3LZt22jQoAEGg6G0dnnbJFGLiiDzfCFfrzzAD6sPkV9kuqc7NsKPQXHhhAW4/cvWQghbU5LcJF1OhSgHPJztGdwmnBWDWvJ0k2B0Wg2LkzJo88VK3vhjG8fOnv/3nQghyiVJ1EKUIwEejox8vA6LXnuAR+oEoBTM2HKMh8as4P2/dnMmt8DaIQohSpkkaiHKoZq+rnzVrSFz+sTQvKYPBQYjP6w5xAOjlzF+yT5yLxs9TQhRvpWo1/fjjz9+w/Xnzp27nViEECVUt6onv77YlFX7TjFqwR52nchibPxeflp3hP6tavFU42Ac7OT7uBDlWYkStYeHx7+uf/bZZ28rICFEyWg0Gh6o7ct9tSrx945UPluUzJHT5xk2ZxffrzrEG61r0z46SGb8EqKcKtVe37ZIen2Lu01BkZHfE1L4Ysl+TuXkAxAV5M5bbcJ5ILSS3IMthA2QXt9C3MUc7LR0b1aNFYNa8Gbr2rjp7dh1IoseP2zkme82kHj0nLVDFEKUgCRqISooF70dfR8KZcVbLXnxvuo46LSsO3iajhPX0OuXzey/xtClQgjbI4laiArO28WBdx6NZNmgFnRpWAWtBubvTCNu3ErenrGdE+euPeuXEMI2yDVqIe4ye9OzGb0gmcVJ6eZloX6uNKrmRaMQbxpV8yLY21muZQtRhsp8mkshRPlV29+N73s0YtPhM4xemMzGQ2fMs3j9tvEoAL5uehqFeNGomjeNq3kREeiOvcydLYRVSKIW4i7VqJo3f7zSjNM5+Ww+cpZNR86y6fAZdhzP5GR2PvN3pjF/ZxoATvY66gd7mpN3/WBP3BztrfwOhLg7lKtE/cknnzBkyBAGDBjAuHHjrB2OEBWCj6ue1lEBtI4KACCv0MD2Y5kkHD5jSuCHz5CVV8TaA6dZe+A0AFoNhAe407iaFw0vtroDPZys+TaEqLDKTaJOSEjgm2++ITo62tqhCFGhOdrraFLdmybVTdNoGo2K/SdzSDh8hk2Hz7LpyBmOnrnA7tQsdqdm8eO6IwBU9nQyXeeu5k2jEC9q+7uhk0FWhLht5SJR5+Tk0K1bN7777js+/PBDa4cjxF1Fq9VQ29+N2v5udGsaAkB6Vh6bDp81Je8jZ9h9Iovj5y5wPPECcxJPAODmaEercD+eaRpC42pe0jlNiFtULhJ1nz59aNeuHbGxsZKohbAB/u6OtIsOpF10IAA5+UUkppxj0xFTq3trylmy84qYnXiC2YknCPVz5ekmwXRuUAUPZ7m2LURJ2HyinjZtGlu2bCEhIeGmyufn55Ofn29+nZ2dXVahCSEuctXbcV9oJe4LrQRAkcHItmOZTN90lDmJJ9iXkcP7f+9m1II9tIsOpFvTYBoESytbiJth04n66NGjDBgwgPj4eBwdHW9qm5EjRzJixIgyjkwIcSN2Oi0NQ7xoGOLF0HYRzE48wdQNKSSlZjFzy3FmbjlOeIAbTzcJplODyrhLD3IhrsumBzyZPXs2nTp1QqfTmZcZDAY0Gg1arZb8/HyLdXB1i/r48eNERkbKgCdCWJlSiq1HzzF1Qwp/bz9BXqERAEd7Le2jg3imaTD1qnpKK1vcFUoy4IlNJ+rs7GyOHDlisey5554jPDycwYMHc8899/zrPmRkMiFsT+aFQmZtOcbUjSnsTS8eczwy0J2nmwbTsV6Q3KctKrQKMzKZm5vbVcnYxcUFHx+fm0rSQgjb5OFkT8+Y6vRoXo3NR84ydWMK/2xPZXdqFu/O3snIeUk8VtfUyo6u4mntcIWwKptO1EKIik2j0Zjuu67mzbBHI5m55Ti/bjjCgZO5TEs4yrSEo9xT2Z1nmoTQoV4QLnr5yBJ3H5s+9V0a5NS3EOWLUoqNh84wdWMK83ekUWAwXct2cdDRoX5lnmkSzD2VPf51H/lFRvKLjBQUGckvMpheF172/PJ1hcaLywzU9ncjplalO/FWxV2swlyjLg2SqIUov87kFjBj8zF+25jCwVO55uVh/m44OujILzRcTLbFifZSAr4dj0YH8kGHe/BycbjdtyDENUmivowkaiHKP6UU6w6eZuqGFBbuSqPQULKPLb2d1vSw1xU/t9PhcMVypWBZcgYGo6KSq56Rj9fh4Uj/MnpX4m5WYTqTCSEEmK5lN69ZieY1K3EqJ59Nh89ip9Wgt78i4V4jGdvrNCW65Wvb0XO8OX0b+zJyeOmnTTzeoDLvPRolI6oJq5EWtRBCXCGv0MDni/fy3cqDGBX4u+sZ1TmaFmF+1g5NVBAlyU0yE7wQQlzB0V7HkLYRTH+1OdUruZCelU/PyQm8PWM72XmF1g5P3GUkUQshxHU0DPFiXv/7eT6mOhoNTEs4Sptxq1iz/5S1QxN3EUnUQghxA04OOoa1j2TaS/dS1duJ4+cu0O37Dbw7eye5+UXWDk/cBSRRCyHETWhaw4cFAx7gP/cGA/Dz+iO0/WIVGw+dsXJkoqKTRC2EEDfJRW/Hhx3r8MsLTans6UTKmfM8+e06Pvh7N3mFBmuHJyooSdRCCFFC94VWYsHA+3myUVWUgv+tPsQjX6xiS8pZa4cmKiBJ1EIIcQvcHO0Z1SWayT0b4++u5+CpXLpMWssn8/eQXySta1F6JFELIcRtaBnux6KBD/J4/coYFXy94gDtv1zNjmOZ1g5NVBCSqIUQ4jZ5ONsz9sl6fNu9IZVcHdibnkPHr9YwdlHybY87LoQkaiGEKCWtowJY9NqDtIsOxGBUjF+6n44T15CUmmXt0EQ5JolaCCFKkbeLAxOfacCEZ+rj5WzP7tQsHpuwmglL91FokNa1KDlJ1EIIUQYejQ5i0WsP0jrSn0KDYsyivdz78RKGzdnJ5iNnqeDTLIhSJLNnCSFEGfF10/NN94bMSTzBh/8kcSonn5/WHeGndUeo6u1Eh7qV6Vg/iFp+btYOVdgwmT1LCCHugCKDkdX7TzE38QQLd6WRW1B8C1dUkDsd61Wmfd0gAjwcrRiluFNkPmohhLAxdjotLcL8aBHmx4UCA/FJ6czZepwVe0+y60QWu05k8fH8JO6t7kPH+kG0uScQDyeZA1tIi1oIIazqbG4B/+xIZU7icRIOF49s5qDT0jLcl471KtMy3A9He50VoxSlTVrUQghRTni5OPCfe0P4z70hHD1znrnbTjAn8Th703NYuCudhbvScXO0o+09AXSsV5mmNXzQaTXWDlvcQdKiFkIIG6OUYk9aNrMTjzM38QSpmXnmdf7uetpHB9GxfmWigtzRaCRpl0clyU2SqIUQwoYZjYqNh88wJ/EE83akknmh0Lyupq8LHepVpkO9IEJ8XKwYpSgpSdSXkUQthKgo8osMrEg+yZzEEyxOSif/suFJw/zdaBXhR2ykP/WqeKKV0+M2Ta5RCyFEBaS309E6KoDWUQFk5xWycFc6cxKPs/bAaZLTs0lOz+ar5Qeo5OpAyzBT0r4/tBLODvJRX55Ji1oIIcq5c+cLWJ58ksVJ6axIPkl2fpF5nYOdlpiaPrSK8KdVhB+BHk5WjFRcIqe+LyOJWghxNykoMpJw+AyLk9JZnJTO0TMXLNbfU9mdVuH+PBzpL53RrKjCJOqRI0cyc+ZM9uzZg5OTE82bN2fUqFGEhYXd9D4kUQsh7lZKKfZl5BC/O50lSelsPXqOyz/xA9wdeSjCj4cj/GlW00fu1b6DKkyibtOmDU899RSNGzemqKiI//73v+zcuZPdu3fj4nJzPRwlUQshhMmpnHyW7slgSVI6K/ee4kJh8TCmTvY67g+tRGyEPy3D/fB101sx0oqvwiTqK508eRI/Pz9WrFjBAw88cFPbSKIWQoir5RUaWHfwNEuS0lm8O4O0rOJ7tTUaqFfVk9gI0ynyUD9XOUVeyipsr+/MzEwAvL29rRyJEEKUb472OlqG+dEyzI8POih2nchicVI6S5Iy2HE8k60p59iaco5PFyZTzceZ1lEBxEX5U7+ql9z6dYeVmxa10Wjkscce49y5c6xevfq65fLz88nPzze/Pn78OJGRkdKiFkKIm5SWmceSPeks3p3Omv2nKTAU369dyVXPw5H+xEWZrmvr7eS69q2okKe+e/Xqxfz581m9evUN39Tw4cMZMWLEVcslUQshRMnl5BexIvkki3ansTQpw+LWL1e9HS3D/Wgd6U+LMF/cHGW2r5tV4RJ13759mTNnDitXrqR69eo3LCstaiGEKBsFRUbWHzzNot1pLNqVTkZ28Wetg05L81o+tI4M4OFIf+mM9i8qTKJWStGvXz9mzZrF8uXLCQ0NLfE+pDOZEEKUPqNRse3YORbuSmfRrjQOnso1r9NooEGwF3FR/rSODKBaJRmH/EoVJlH37t2bqVOnMmfOHIt7pz08PHByurnRdSRRCyFE2dufkW1O2tuOZVqsC/N3o3WUP3FRATLIykUVJlFf75c5efJkevbseVP7kEQthBB3VmrmBeJ3p7NoVzrrD56myFicZoI8HC+OV+5P42re2Ou0VozUeipMoi4NkqiFEMJ6Ms8XsjTZlLSXJ5+0GGTFTW/H/bUr0SLMjxZhvvi5OVox0jurwt5HLYQQonzxcLanU/0qdKpfhbxCA6v3nWLR7jSWJGVwOreAeTvSmLcjDYA6lT1oGeZLi3A/6lbxRCf3awOSqIUQQtwhjvY6YiP9iY30x2hUbD+eybI9GSxPzmDbsUx2HDc9xi/dj5ezPQ/W9qVluB8PhPri5eJg7fCtRk59CyGEsLqT2fms2HuSZckZrNx7kuy84vu1tRqoH+xlam2H+VWIDmlyjfoykqiFEKJ8KTIY2ZJyjmXJGSzbk8GetGyL9X5uelqE+dIyzI+Y0Eq4l8OBViRRX0YStRBClG+pmRdYnnySZXsyWL3/FOcLijuk2Wk1NKrmZRq3PNyv3EwgIon6MpKohRCi4sgvMpBw6KyptZ2cwcGTuRbrK3s68WCYLzE1K3FvDW98XG1zhDRJ1JeRRC2EEBXXkdO5ptZ2cgbrDpwmv8hosT4i0J3mNX1oXtOHJtW9bWY8cknUl5FELYQQd4cLBQbWHTzFqn2nWHfg9FXXtnVaDdFVPC4m7ko0DPHC0d46s3/JfdRCCCHuOk4OOh4K9+ehcH8ATuXks/7gadYeOM3a/ac4fPq8eZ7ticsO4KDT0iDEk5ialWhey4foKp42OVKatKiFEELcFY6fu8C6A6dZe+AUa/efJi0rz2K9s4OOJtW9zS3uyEB3tGU06Iq0qIUQQogrVPZ0okvDKnRpWAWlFIdO5bL2wGlz8j57vpDlySdZnnwSAE9ne+6t7kPzWqZr3DV9rdOjXBK1EEKIu45Go6GGrys1fF35z70hGI2KPWnZrD1gur694dAZzp0vZMGuNBbsMg1x6uem5/5QX8Y8EX1HE7YkaiGEEHc9rVZDZJA7kUHuvHh/DYoMRrYfzzS3tjcdPktGdj4HT+Xc8Va1JGohhBDiCnY6LQ2CvWgQ7EWflrXIKzSwNeUcBuOd79YliVoIIYT4F472OprV9LHKsW2vH7oQQgghzCRRCyGEEDZMErUQQghhwyRRCyGEEDZMErUQQghhwyp8r2+j0TSTSmpqqpUjEUIIIUwu5aRLOepGKnyiTk9PB6BJkyZWjkQIIYSwlJ6eTnBw8A3LVPhJOYqKiti6dSv+/v5otbd3pj87O5vIyEh2796Nm5tbKUVYsUmdlZzUWclJnZWc1FnJlWadGY1G0tPTqV+/PnZ2N24zV/hEXZqysrLw8PAgMzMTd3d3a4dTLkidlZzUWclJnZWc1FnJWavOpDOZEEIIYcMkUQshhBA2TBJ1Cej1et577z30er21Qyk3pM5KTuqs5KTOSk7qrOSsVWdyjVoIIYSwYdKiFkIIIWyYJGohhBDChkmiFkIIIWyYJOoSmDhxItWqVcPR0ZGmTZuyceNGa4dks0aOHEnjxo1xc3PDz8+Pjh07kpycbO2wyo1PPvkEjUbDwIEDrR2KTTt+/Dj/+c9/8PHxwcnJiTp16rBp0yZrh2WzDAYD7777LtWrV8fJyYmaNWvywQcfIF2VLK1cuZL27dsTFBSERqNh9uzZFuuVUgwbNozAwECcnJyIjY1l3759ZRaPJOqb9Pvvv/P666/z3nvvsWXLFurWrUtcXBwZGRnWDs0mrVixgj59+rB+/Xri4+MpLCykdevW5ObmWjs0m5eQkMA333xDdHS0tUOxaWfPniUmJgZ7e3vmz5/P7t27+eyzz/Dy8rJ2aDZr1KhRTJo0iQkTJpCUlMSoUaMYPXo0X375pbVDsym5ubnUrVuXiRMnXnP96NGjGT9+PF9//TUbNmzAxcWFuLg48vLyyiYgJW5KkyZNVJ8+fcyvDQaDCgoKUiNHjrRiVOVHRkaGAtSKFSusHYpNy87OVqGhoSo+Pl49+OCDasCAAdYOyWYNHjxY3XfffdYOo1xp166dev755y2WPf7446pbt25Wisj2AWrWrFnm10ajUQUEBKhPP/3UvOzcuXNKr9er3377rUxikBb1TSgoKGDz5s3Exsaal2m1WmJjY1m3bp0VIys/MjMzAfD29rZyJLatT58+tGvXzuJvTVzb3LlzadSoEU888QR+fn7Ur1+f7777ztph2bTmzZuzZMkS9u7dC8C2bdtYvXo1bdu2tXJk5cehQ4dIS0uz+B/18PCgadOmZZYPKvzsWaXh1KlTGAwG/P39LZb7+/uzZ88eK0VVfhiNRgYOHEhMTAz33HOPtcOxWdOmTWPLli0kJCRYO5Ry4eDBg0yaNInXX3+d//73vyQkJNC/f38cHBzo0aOHtcOzSW+//TZZWVmEh4ej0+kwGAx89NFHdOvWzdqhlRtpaWkA18wHl9aVNknUosz16dOHnTt3snr1amuHYrOOHj3KgAEDiI+Px9HR0drhlAtGo5FGjRrx8ccfA1C/fn127tzJ119/LYn6Ov744w9+/fVXpk6dSlRUFImJiQwcOJCgoCCpMxsmp75vQqVKldDpdOa5rS9JT08nICDASlGVD3379uXvv/9m2bJlVKlSxdrh2KzNmzeTkZFBgwYNsLOzw87OjhUrVjB+/Hjs7OwwGAzWDtHmBAYGEhkZabEsIiKClJQUK0Vk+wYNGsTbb7/NU089RZ06dejevTuvvfYaI0eOtHZo5calz/w7mQ8kUd8EBwcHGjZsyJIlS8zLjEYjS5YsoVmzZlaMzHYppejbty+zZs1i6dKlVK9e3doh2bRWrVqxY8cOEhMTzY9GjRrRrVs3EhMT0el01g7R5sTExFx1y9/evXsJCQmxUkS27/z582i1lh/7Op0Oo9FopYjKn+rVqxMQEGCRD7KystiwYUOZ5QM59X2TXn/9dXr06EGjRo1o0qQJ48aNIzc3l+eee87aodmkPn36MHXqVObMmYObm5v52o2HhwdOTk5Wjs72uLm5XXX93sXFBR8fH7mufx2vvfYazZs35+OPP6Zr165s3LiRb7/9lm+//dbaodms9u3b89FHHxEcHExUVBRbt25l7NixPP/889YOzabk5OSwf/9+8+tDhw6RmJiIt7c3wcHBDBw4kA8//JDQ0FCqV6/Ou+++S1BQEB07diybgMqkL3kF9eWXX6rg4GDl4OCgmjRpotavX2/tkGwWcM3H5MmTrR1auSG3Z/27v/76S91zzz1Kr9er8PBw9e2331o7JJuWlZWlBgwYoIKDg5Wjo6OqUaOGGjp0qMrPz7d2aDZl2bJl1/z86tGjh1LKdIvWu+++q/z9/ZVer1etWrVSycnJZRaPzJ4lhBBC2DC5Ri2EEELYMEnUQgghhA2TRC2EEELYMEnUQgghhA2TRC2EEELYMEnUQgghhA2TRC2EEELYMEnUQgghhA2TRC2EKHUajYbZs2dbOwwhKgRJ1EJUMD179kSj0Vz1aNOmjbVDE0LcApmUQ4gKqE2bNkyePNlimV6vt1I0QojbIS1qISogvV5PQECAxcPLywswnZaeNGkSbdu2xcnJiRo1avDnn39abL9jxw4eeughnJyc8PHx4eWXXyYnJ8eizA8//EBUVBR6vZ7AwED69u1rsf7UqVN06tQJZ2dnQkNDmTt3rnnd2bNn6datG76+vjg5OREaGnrVFwshhIkkaiHuQu+++y6dO3dm27ZtdOvWjaeeeoqkpCQAcnNziYuLw8vLi4SEBKZPn87ixYstEvGkSZPo06cPL7/8Mjt27GDu3LnUqlXL4hgjRoyga9eubN++nUceeYRu3bpx5swZ8/F3797N/PnzSUpKYtKkSVSqVOnOVYAQ5UmZzcslhLCKHj16KJ1Op1xcXCweH330kVLKNAXpq6++arFN06ZNVa9evZRSSn377bfKy8tL5eTkmNf/888/SqvVqrS0NKWUUkFBQWro0KHXjQFQ77zzjvl1Tk6OAtT8+fOVUkq1b99ePffcc6XzhoWo4OQatRAVUMuWLZk0aZLFMm9vb/PzZs2aWaxr1qwZiYmJACQlJVG3bl1cXFzM62NiYjAajSQnJ6PRaDhx4gStWrW6YQzR0dHm5y4uLri7u5ORkQFAr1696Ny5M1u2bKF169Z07NiR5s2b39J7FaKik0QtRAXk4uJy1ano0uLk5HRT5ezt7S1eazQajEYjAG3btuXIkSPMmzeP+Ph4WrVqRZ8+fRgzZkypxytEeSfXqIW4C61fv/6q1xEREQBERESwbds2cnNzzevXrFmDVqslLCwMNzc3qlWrxpIlS24rBl9fX3r06MEvv/zCuHHj+Pbbb29rf0JUVNKiFqICys/PJy0tzWKZnZ2ducPW9OnTadSoEffddx+//vorGzdu5H//+x8A3bp147333qNHjx4MHz6ckydP0q9fP7p3746/vz8Aw4cP59VXX8XPz4+2bduSnZ3NmjVr6Nev303FN2zYMBo2bEhUVBT5+fn8/fff5i8KQghLkqiFqIAWLFhAYGCgxbKwsDD27NkDmHpkT5s2jd69exMYGMhvv/1GZGQkAM7OzixcuJABAwbQuHFjnJ2d6dy5M2PHjjXvq0ePHuTl5fH555/z5ptvUqlSJbp06XLT8Tk4ODBkyBAOHz6Mk5MT999/P9OmTSuFdy5ExaNRSilrByGEuHM0Gg2zZs2iY8eO1g5FCHET5Bq1EEIIYcMkUQshhBA2TK5RC3GXkatdQpQv0qIWQgghbJgkaiGEEMKGSaIWQgghbJgkaiGEEMKGSaIWQgghbJgkaiGEEMKGSaIWQgghbJgkaiGEEMKGSaIWQgghbNj/Adhvg9eKjj6cAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen: int, tokens_seen: int, train_losses: List[float], val_losses: List[float]) -> None:\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 从上面的结果可以看到模型最初生成的是难以理解的词语字符串，而到了后期，它能够生成语法上或多或少正确的句子\n",
    "- 然而，根据训练集和验证集的损失，可以看到模型开始出现过拟合\n",
    "- 如果检查它在训练结束时写出的几段文字，会发现它们完全照搬自训练集中的内容——模型只是简单地记忆了训练数据\n",
    "- 稍后将介绍一些解码策略，这些策略可以在一定程度上缓解这种记忆现象\n",
    "- 注意，这里出现的过拟合是因为训练集非常非常小，而且对它进行了多次迭代\n",
    "  - 这里的LLM训练主要是出于教育目的，主要想看到模型能够学习生成连贯的文本\n",
    "  - 不可能花费数周或数月的时间在大量昂贵的硬件上训练这个模型，而是在后面加载预训练权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-2.webp\" width=800px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**如果对使用更高级的技术来增强这个训练函数感兴趣，例如学习率预热、余弦退火和梯度裁剪，请参考[Appendix D](../../appendix-D/01_main-chapter-code)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**如果对更大的训练数据集和更长时间的训练运行感兴趣，请看靠[../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosyvoice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
